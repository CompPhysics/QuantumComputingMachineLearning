<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week2.do.txt --pygments_html_style=default --html_style=bloodish --html_links_in_new_window --html_output=week2 --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="January 30-February 3,2023: Quantum Computing, Quantum Machine Learning and Quantum Information Theories">
<title>January 30-February 3,2023: Quantum Computing, Quantum Machine Learning and Quantum Information Theories</title>
<style type="text/css">
/* bloodish style */
body {
  font-family: Helvetica, Verdana, Arial, Sans-serif;
  color: #404040;
  background: #ffffff;
}
h1 { font-size: 1.8em; color: #8A0808; }
h2 { font-size: 1.6em; color: #8A0808; }
h3 { font-size: 1.4em; color: #8A0808; }
h4 { font-size: 1.2em; color: #8A0808; }
a { color: #8A0808; text-decoration:none; }
tt { font-family: "Courier New", Courier; }
p { text-indent: 0px; }
hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
p.caption { width: 80%; font-style: normal; text-align: left; }
hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa; }div.highlight {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    line-height: 1.21429em;
}
div.cell {
    width: 100%;
    padding: 5px 5px 5px 0;
    margin: 0;
    outline: none;
}
div.input {
    page-break-inside: avoid;
    box-orient: horizontal;
    box-align: stretch;
    display: flex;
    flex-direction: row;
    align-items: stretch;
}
div.inner_cell {
    box-orient: vertical;
    box-align: stretch;
    display: flex;
    flex-direction: column;
    align-items: stretch;
    box-flex: 1;
    flex: 1;
}
div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 4px;
    background: #f7f7f7;
    line-height: 1.21429em;
}
div.input_area > div.highlight {
    margin: .4em;
    border: none;
    padding: 0;
    background-color: transparent;
}
div.output_wrapper {
    position: relative;
    box-orient: vertical;
    box-align: stretch;
    display: flex;
    flex-direction: column;
    align-items: stretch;
}
.output {
    box-orient: vertical;
    box-align: stretch;
    display: flex;
    flex-direction: column;
    align-items: stretch;
}
div.output_area {
    padding: 0;
    page-break-inside: avoid;
    box-orient: horizontal;
    box-align: stretch;
    display: flex;
    flex-direction: row;
    align-items: stretch;
}
div.output_subarea {
    padding: .4em .4em 0 .4em;
    box-flex: 1;
    flex: 1;
}
div.output_text {
    text-align: left;
    color: #000;
    line-height: 1.21429em;
}
.alert-text-small   { font-size: 80%;  }
.alert-text-large   { font-size: 130%; }
.alert-text-normal  { font-size: 90%;  }
.alert {
  padding:8px 35px 8px 14px; margin-bottom:18px;
  text-shadow:0 1px 0 rgba(255,255,255,0.5);
  border:1px solid #bababa;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  -moz-border-radius: 4px;
  color: #555;
  background-color: #f8f8f8;
  background-position: 10px 5px;
  background-repeat: no-repeat;
  background-size: 38px;
  padding-left: 55px;
  width: 75%;
 }
.alert-block {padding-top:14px; padding-bottom:14px}
.alert-block > p, .alert-block > ul {margin-bottom:1em}
.alert li {margin-top: 1em}
.alert-block p+p {margin-top:5px}
.alert-notice { background-image: url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_gray_notice.png); }
.alert-summary  { background-image:url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_gray_summary.png); }
.alert-warning { background-image: url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_gray_warning.png); }
.alert-question {background-image:url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_gray_question.png); }
div { text-align: justify; text-justify: inter-word; }
.tab {
  padding-left: 1.5em;
}
div.toc p,a {
  line-height: 1.3;
  margin-top: 1.1;
  margin-bottom: 1.1;
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Overview, Composite Systems and Tensor Products',
               2,
               None,
               'overview-composite-systems-and-tensor-products'),
              ('Summary from last week', 2, None, 'summary-from-last-week'),
              ('Definition of Computational basis states, repetition from last '
               'week',
               2,
               None,
               'definition-of-computational-basis-states-repetition-from-last-week'),
              ('Superposition and more', 3, None, 'superposition-and-more'),
              ('Tensor products', 2, None, 'tensor-products'),
              ('Measurements', 2, None, 'measurements'),
              ('Possible measurement', 2, None, 'possible-measurement'),
              ('Different operators and gates',
               2,
               None,
               'different-operators-and-gates'),
              ('Other important matrices', 3, None, 'other-important-matrices'),
              ('Representation of states and Hamiltonians',
               3,
               None,
               'representation-of-states-and-hamiltonians'),
              ('Preparing for later studies: varying the coefficients of a '
               'wave function expansion and orthogonal transformations',
               2,
               None,
               'preparing-for-later-studies-varying-the-coefficients-of-a-wave-function-expansion-and-orthogonal-transformations')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "AMS"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- ------------------- main content ---------------------- -->
<center>
<h1>January 30-February 3,2023: Quantum Computing, Quantum Machine Learning and Quantum Information Theories</h1>
</center>  <!-- document title -->

<!-- author(s): Morten Hjorth-Jensen -->
<center>
<b>Morten Hjorth-Jensen</b> [1, 2]
</center>
<!-- institution(s) -->
<center>
[1] <b>Department of Physics, University of Oslo, Norway</b>
</center>
<center>
[2] <b>Department of Physics and Astronomy and Facility for Rare Isotope Beams, Michigan State University, USA</b>
</center>
<br>
<center>
<h4>Jan 29, 2023</h4>
</center> <!-- date -->
<br>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="overview-composite-systems-and-tensor-products">Overview, Composite Systems and Tensor Products   </h2>

<div class="alert alert-block alert-block alert-text-normal">
<b>Composite systems and Tensor products</b>
<p>
<ol>
 <li> Tensor products of Hilbert Spaces and definition of Computational Basis, partly repetition from last week</li>
 <li> Quantum operations and special matrices</li>
 <li> Simple Hamiltonians and other operators</li>
 <li> First exercise set</li>
</ol>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="summary-from-last-week">Summary from last week </h2>

<p>Last week we:</p>
<ol>
<li> defined the state vector and the associated notation</li>
<li> introduced the inner product and showed how to calculate it in an orthonormal basis</li>
<li> introduced outer products and projection operators</li>
<li> introduced tensor products and showed how to contruct state vectors for multiple qubits</li>
</ol>
<p>We will repeat some of these topics today and discuss also </p>
<ol>
<li> quantum measurements are probabilistic</li>
<li> the idea of wavefunction collapse as a result of measurement Next lecture we will:</li>
</ol>
<h2 id="definition-of-computational-basis-states-repetition-from-last-week">Definition of Computational basis states, repetition from last week </h2>

<!-- to do: make figures with examples of basis states, hydrogen like systems, harmonic oscillator -->
<p>Assume we have a two-level system where the two states are represented
by the state vectors \( \vert \phi_0\rangle \) and \( \vert \phi_1\rangle \),
respectively. These states could represent selected or effective
degrees of freedom for either a single particle (fermion or boson) or
they could represent effective many-body degrees of freedon. In actual
realizations of quantum computing we search often for candidate
systems where we can use some low-lying states as computational basis
states. But we are not limited to quantum computing. When doing
many-body physics, due to the exploding degrees of freedom, we
normally search after effective ways by which we can reduce the
involved dimensionalities to a number of degrees of freedom we can
handle by a given many-body method.
</p>

<!-- to add === Examples: Hydrogen like states and the harmonic oscillator in one, two and three dimensions === -->

<p>We will now relabel the above two states as two orthogonal and normalized basis (ONB) states </p>
$$
\vert \phi_0 \rangle = \vert 0 \rangle = \begin{bmatrix} 1 \\ 0 \end{bmatrix},
$$

<p>and </p>
$$
\vert \phi_1 \rangle = \vert 1 \rangle = \begin{bmatrix} 0 \\ 1 \end{bmatrix}.
$$

<p>It is straight forward to see that \( \langle 1 \vert 0\rangle=0 \). With these two states we can define the define the identity operator \( \boldsymbol{I} \) as the sum of the outer products of these two states, namely</p>
$$
\boldsymbol{I} = \sum_{i=0}^{i=1}\vert i\rangle \langle i\vert = \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix} +\begin{bmatrix} 0 & 0 \\ 0 & 1 \end{bmatrix}=\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}.
$$

<p>We can further define the projection operators</p>
$$
\boldsymbol{P} = \vert 0\rangle \langle 0\vert = \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix},
$$

<p>and </p>
$$
\boldsymbol{Q} = \vert 1\rangle \langle 1\vert = \begin{bmatrix} 0 & 0 \\ 0 & 1 \end{bmatrix}.
$$

<p>We note that \( P^2=P \), \( Q^2=Q \) (the operators are idempotent) and that
their determinants are zero, meaning in turn that we cannot use these
operators for unitary/orthogonal transformations. However, they play
important roles in defining effective Hilbert spaces for many-body
studies. Finally, before proceeding we note also that the two matrices
commute and we have \( \boldsymbol{P}\boldsymbol{Q}=0 \) and \( \left[ \boldsymbol{P},\boldsymbol{Q}\right]=0 \).
</p>
<h3 id="superposition-and-more">Superposition and more </h3>

<p>Using the properties of ONBs we can expand a new state in terms of the
above states. These states could also form  a basis which is an
eigenbasis of a selected Hamiltonian (more of this below).
</p>

<p>We define now a new state which is a linear expansion in terms of
these computational basis states
</p>

$$
\vert \psi \rangle = \alpha \vert 0 \rangle + \beta\vert 1 \rangle,
$$

<p>where the coefficients \( \alpha = \langle 0 \vert \psi \rangle \) and
\( \beta =\langle 1 \vert \psi\rangle \) reresent the overlaps between the
computational basis states and the state \( \vert \psi\rangle \). In quantum speech, we say the state is in a superposition of the states \( \vert 0\rangle \) and \( \vert 1\rangle \).
</p>

<p>Computing the inner product of \( \vert \psi \rangle \) we obtain</p>
$$
\langle \psi \vert \psi \rangle = \vert \alpha \vert ^2\langle 0\vert 0\rangle + \vert \beta \vert ^2\langle 1\vert 1\rangle = \vert \alpha \vert ^2 + \vert \beta \vert ^2 = 1,
$$

<p>since the new basis, which is defined in terms of a a unitary/orthogonal
transformation, preserves the orthogonality and norm of the original
computational basis \( \vert 0\rangle \) and \( \vert 1\rangle \). To see
this, consider the unitary transformation (show derivation of
preserving orthogonality).
</p>

<p>If we now act with the projection operators \( \boldsymbol{P} \) and \( \boldsymbol{Q} \) on
the state \( \vert \psi\rangle \) we get
</p>

$$
\boldsymbol{P}\vert \psi \rangle = \vert 0 \rangle\langle 0\vert (\alpha \vert 0 \rangle + \beta\vert 1 \rangle)=\alpha \vert 0\rangle,
$$

<p>that is we <b>project</b> out the \( \vert 0\rangle \) component of the state
\( \vert \psi\rangle \) with the coefficient \( \alpha \) while \( \boldsymbol{Q} \)
projects out the \( \vert 1\rangle \) component with coefficient \( \beta \)
as seen from
</p>

$$
\boldsymbol{Q}\vert \psi \rangle = \vert 1 \rangle\langle 1\vert (\alpha \vert 0 \rangle + \beta\vert 1 \rangle)=\beta \vert 1\rangle.
$$

<p>The above results can easily be derived by multiplying the pertinent
matrices with the vectors \( \vert 0\rangle \) and \( \vert 1\rangle \),
respectively.
</p>

<p>Using the above linear expansion we can now define the density matrix of the state \( \vert \psi\rangle \) as the outer product</p>
$$
\boldsymbol{\rho}=\vert \psi \rangle\langle \psi \vert = \alpha\alpha^* \vert 0 \rangle\langle 0\vert+\alpha\beta^* \vert 0 \rangle\langle 1\vert+\beta\alpha^* \vert 1 \rangle\langle 0\vert+\beta\beta^* \vert 1 \rangle\langle 1\vert=\begin{bmatrix} \alpha\alpha^* & \alpha\beta^*\\ \beta\alpha^* & \beta\beta^*\end{bmatrix}.
$$

<p>Finally, we note that the trace of the density matrix is simply given by unity</p>
$$
\mathrm{tr}\boldsymbol{\rho}=\alpha\alpha^* +\beta\beta^*=1.
$$
<h2 id="tensor-products">Tensor products </h2>

<p>Consider now two vectors with length \( n=2 \), with elements</p>

$$
\vert x \rangle = \begin{bmatrix} x_0 \\ x_1 \end{bmatrix}, 
$$

<p>and</p>
$$
\vert x \rangle = \begin{bmatrix} y_0 \\ y_1 \end{bmatrix}. 
$$

<p>The tensor product of these two vectors is defined as</p>
$$
\vert x \rangle \otimes \vert y \rangle = \vert xy \rangle  = \begin{bmatrix} x_0y_0 \\ x_0y_1 \\ x_1y_0 \\ x_1y_1 \end{bmatrix}, 
$$

<p>which is now a vector of length \( 4 \).</p>

<p>If we now go back to our original one-qubit basis states, we can form teh following tensor products</p>
$$
\vert 0 \rangle \otimes \vert 0 \rangle = \begin{bmatrix} 1 \\ 0\end{bmatrix} \otimes \begin{bmatrix} 1 \\ 0\end{bmatrix} =\begin{bmatrix} 1 \\ 0 \\ 0 \\ 0 \end{bmatrix}=\vert 00 \rangle, 
$$

$$
\vert 0 \rangle \otimes \vert 1 \rangle = \begin{bmatrix} 1 \\ 0\end{bmatrix} \otimes \begin{bmatrix} 0 \\ 1\end{bmatrix} =\begin{bmatrix} 0 \\ 1 \\ 0 \\ 0 \end{bmatrix}=\vert 01 \rangle, 
$$

$$
\vert 1 \rangle \otimes \vert 0 \rangle = \begin{bmatrix} 0 \\ 1\end{bmatrix} \otimes \begin{bmatrix} 1 \\ 0\end{bmatrix} =\begin{bmatrix} 0 \\ 0 \\ 1 \\ 0 \end{bmatrix}=\vert 10 \rangle, 
$$

<p>and finally</p>
$$
\vert 1 \rangle \otimes \vert 1 \rangle = \begin{bmatrix} 0 \\ 1\end{bmatrix} \otimes \begin{bmatrix} 0 \\ 1\end{bmatrix} =\begin{bmatrix} 0 \\ 0 \\ 0 \\ 1 \end{bmatrix}=\vert 11 \rangle. 
$$

<p>We have now four different states and we could try to make a new list
by relabeling the states as follows \( \vert 00 \rangle =\vert 0
\rangle \), \( \vert 01 \rangle =\vert 1 \rangle \), \( \vert 10 \rangle
=\vert 2 \rangle \), \( \vert 11 \rangle =\vert 3 \rangle \).
</p>

<p>In similar ways we can define the tensor product of three qubits (or single-particle states) as</p>
$$
\vert 0 \rangle \otimes \vert 0 \rangle \otimes \vert 0 \rangle = \begin{bmatrix} 1 \\ 0\end{bmatrix} \otimes \begin{bmatrix} 1 \\ 0\end{bmatrix} \otimes \begin{bmatrix} 1 \\ 0\end{bmatrix}=\begin{bmatrix} 1 \\ 0 \\ 0 \\ 0 \\ 0 \\0 \\ 0 \\ 0\end{bmatrix}=\vert 000 \rangle, 
$$

<p>which is a new vector of length eight. We note that with a single-particle basis given the states \( \vert 0\rangle \) and \( \vert 1\rangle \) we can, with \( N \) particles construct \( 2^N \) different states.
This is something we can generalize to
</p>
<ul>
 <li> discuss ways of labeling states</li>
 <li> how to write a code which does it</li>
</ul>
<p>The tensor product of two \( 2\times 2 \) matrices \( \boldsymbol{A} \) and \( \boldsymbol{B} \) is given by</p>

$$
\boldsymbol{A} \times \boldsymbol{B} = \begin{bmatrix} a_{00} & a_{01} \\ a_{10} & a_{11} \end{bmatrix} \otimes \begin{bmatrix} b_{00} & b_{01} \\ b_{10} & b_{11} \end{bmatrix} =
\begin{bmatrix} a_{00} b_{00} &  a_{00}b_{01} & a_{01} b_{00} & a_{01}b_{01} \\
                a_{00} b_{10} &  a_{00}b_{11} & a_{01} b_{10} & a_{01}b_{11} \\
                a_{10} b_{00} &  a_{10}b_{01} & a_{11} b_{00} & a_{11}b_{01} \\
                a_{10} b_{10} &  a_{10}b_{11} & a_{11} b_{10} & a_{11}b_{11} \end{bmatrix}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="measurements">Measurements </h2>

<p>The probability of a measurement on a quantum system giving a certain
result is determined by the weight of the relevant basis state in
the state vector. After the measurement, the system is in the state
corresponding to the result of the measurement. The operators and gates discussed below are examples of operations we can perform on specific states.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="possible-measurement">Possible measurement </h2>

<p>We can consider the state</p>
$$
\vert \psi\rangle = \alpha \vert 0 \rangle +\beta \vert 1 \rangle
$$


<ol>
<li> A measurement can yield only one of the above states, either \( \vert 0\rangle \) or \( \vert 1\rangle \).</li>
<li> The probability of a measurement resulting in \( \vert 0\rangle \) is \( \alpha^*\alpha = \vert \alpha \vert^* \).</li>
<li> The probability of a measurement resulting in \( \vert 1\rangle \) is \( \beta^*\beta = \vert \beta \vert^* \).</li>
<li> And we note that the sum of the outcomes gives \( $\alpha^*\alpha+\beta^*\beta=1 \) since the two states are normalized.</li>
</ol>
<p>After the measurement, the state of the system is the state associated with the result of the measurement.</p>

<p>We have already encountered the projection operators \( P \) and \( Q \). Let us now look at other types of operations we can make
on qubit states.
</p>
<h2 id="different-operators-and-gates">Different operators and gates </h2>

<p>In quantum computing, the so-called Pauli matrices, and other simple
\( 2\times 2 \) matrices, play an important role, ranging from the setup
of quantum gates to a rewrite of creation and annihilation operators
and other quantum mechanical operators. Let us start with the familiar
Pauli matrices and remind ourselves of some of their basic properties.
</p>

<p>The Pauli matrices are defined as</p>
$$
\sigma_x = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix},
$$

$$
\sigma_y = \begin{bmatrix} 0 & -\imath \\ \imath & 0 \end{bmatrix},
$$

<p>and</p>
$$
\sigma_z = \begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix}.
$$

<p>It is easy to show that the matrices obey the properties (being involutory)</p>
$$
\sigma_x\sigma_x = \sigma_y\sigma_y=\sigma_z\sigma_z = I=\begin{bmatrix} 1 & 0 \\ 0 & 1\end{bmatrix},
$$

<p>that is their products with themselves result in the identity matrix
\( \boldsymbol{I} \).  Furthermore, the Pauli matrices are unitary matrices
meaning that their inverses are equal to their hermitian conjugated
matrices. The determinants of the Pauli matrices are all equal to \( -1 \),
as can be easily verified.
</p>

<p>The Pauli matrices obey also the following commutation rules</p>
$$
\left[\sigma_x,\sigma_y\right] = 2\imath \sigma_z.
$$

<p>Before we proceed with other matrices and how they can be used to
operate on various quantum mechanical states, let us try to define
various basis sets and their pertinent notations. We will often refer
to these basis states as our computational basis.
</p>
<h3 id="other-important-matrices">Other important matrices </h3>

<p>We end with presenting other operators (as matrices) which play an important role in quantum computing, the so-called Hadamard matrix (or gate as we will use later)</p>
$$
\boldsymbol{H}=\frac{1}{\sqrt{2}}\begin{bmatrix} 1 & 1 \\ 1 & -1\end{bmatrix}.
$$

<p>The action of the operator \( \boldsymbol{H} \) on a computational basis state like \( \vert 0\rangle \) gives</p>
$$
\boldsymbol{H}\vert 0 \rangle = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 & 1 \\ 1 & -1\end{bmatrix}\begin{bmatrix} 1 \\ 0\end{bmatrix}=\frac{1}{\sqrt{2}}(\vert 0\rangle + \vert 1\rangle),
$$

<p>and </p>

$$
\boldsymbol{H}\vert 1 \rangle = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 & 1 \\ 1 & -1\end{bmatrix}\begin{bmatrix} 0 \\ 1\end{bmatrix}=\frac{1}{\sqrt{2}}(\vert 0\rangle - \vert 1\rangle),
$$

<p>that is we create a superposition of the states \( \vert 0\rangle \) and \( \vert 1\rangle \).</p>

<p>Another famous operation is the phase matrix given by</p>
$$
\boldsymbol{S} = \begin{bmatrix} 1 & 0 \\ 0 & \imath\end{bmatrix}.
$$
<h3 id="representation-of-states-and-hamiltonians">Representation of states and Hamiltonians </h3>

<p>Before we proceed we need several other definitions.  Throughout these
lectures we will assume that the interacting part of the Hamiltonian
can be approximated by a two-body interaction.  This means that our
Hamiltonian can be written as the sum of a onebody part, which
includes kinetic energy and an eventual external field, and a twobody
interaction
</p>

$$
\begin{equation}
    \hat{H} = \hat{H}_0 + \hat{H}_I 
    = \sum_{i=1}^N \hat{h}_0(x_i) + \sum_{i < j}^N \hat{v}(r_{ij}),
\label{_auto1}
\end{equation}
$$

<p>with </p>
$$
\begin{equation}
  H_0=\sum_{i=1}^N \hat{h}_0(x_i).
\label{hinuclei}
\end{equation}
$$

<p>The onebody part \( u_{\mathrm{ext}}(x_i) \) is normally approximated by a
harmonic oscillator potential or the Coulomb interaction an electron
feels from the nucleus. However, other potentials are fully possible,
such as one derived from the self-consistent solution of the
Hartree-Fock equations.
</p>

<p>Our Hamiltonian is invariant under the permutation (interchange) of
two particles.  Since we deal with fermions however, the total wave
function is antisymmetric.  Let \( \hat{P} \) be an operator which
interchanges two particles.  Due to the symmetries we have ascribed to
our Hamiltonian, this operator commutes with the total Hamiltonian,
</p>

$$
[\hat{H},\hat{P}] = 0,
 $$

<p>meaning that \( \Psi_{\lambda}(x_1, x_2, \dots , x_A) \) is an eigenfunction of 
\( \hat{P} \) as well, that is
</p>
$$
\hat{P}_{ij}\Psi_{\lambda}(x_1, x_2, \dots,x_i,\dots,x_j,\dots,x_A)=
\beta\Psi_{\lambda}(x_1, x_2, \dots,x_i,\dots,x_j,\dots,x_A),
$$

<p>where \( \beta \) is the eigenvalue of \( \hat{P} \). We have introduced the suffix \( ij \) in order to indicate that we permute particles \( i \) and \( j \).
The Pauli principle tells us that the total wave function for a system of fermions
has to be antisymmetric, resulting in the eigenvalue \( \beta = -1 \).   
</p>

<p>In our case we assume that  we can approximate the exact eigenfunction with a Slater determinant</p>
$$
\begin{equation}
   \Phi(x_1, x_2,\dots ,x_A,\alpha,\beta,\dots, \sigma)=\frac{1}{\sqrt{A!}}
\left| \begin{array}{ccccc} \psi_{\alpha}(x_1)& \psi_{\alpha}(x_2)& \dots & \dots & \psi_{\alpha}(x_A)\\
                            \psi_{\beta}(x_1)&\psi_{\beta}(x_2)& \dots & \dots & \psi_{\beta}(x_A)\\  
                            \dots & \dots & \dots & \dots & \dots \\
                            \dots & \dots & \dots & \dots & \dots \\
                     \psi_{\sigma}(x_1)&\psi_{\sigma}(x_2)& \dots & \dots & \psi_{\sigma}(x_A)\end{array} \right|, \label{eq:HartreeFockDet}
\end{equation}
$$

<p>where  \( x_i \)  stand for the coordinates and spin values of a particle \( i \) and \( \alpha,\beta,\dots, \gamma \) 
are quantum numbers needed to describe remaining quantum numbers.  
</p>

<p>If we deal with Fermions (identical and indistinguishable particles) we will 
form an ansatz for a given state in terms of so-called Slater determinants determined
by a chosen basis of single-particle functions. 
</p>

<p>For a given \( n\times n \) matrix \( \mathbf{A} \) we can write its determinant</p>
$$
   det(\mathbf{A})=|\mathbf{A}|=
\left| \begin{array}{ccccc} a_{11}& a_{12}& \dots & \dots & a_{1n}\\
                            a_{21}&a_{22}& \dots & \dots & a_{2n}\\  
                            \dots & \dots & \dots & \dots & \dots \\
                            \dots & \dots & \dots & \dots & \dots \\
                            a_{n1}& a_{n2}& \dots & \dots & a_{nn}\end{array} \right|,
$$

<p>in a more compact form as </p>
$$
|\mathbf{A}|= \sum_{i=1}^{n!}(-1)^{p_i}\hat{P}_i a_{11}a_{22}\dots a_{nn},
$$

<p>where \( \hat{P}_i \) is a permutation operator which permutes the column indices \( 1,2,3,\dots,n \)
and the sum runs over all \( n! \) permutations.  The quantity \( p_i \) represents the number of transpositions of column indices that are needed in order to bring a given permutation back to its initial ordering, in our case given by \( a_{11}a_{22}\dots a_{nn} \) here.
</p>

<p>A simple \( 2\times 2 \) determinant illustrates this. We have</p>
$$
   det(\mathbf{A})=
\left| \begin{array}{cc} a_{11}& a_{12}\\
                            a_{21}&a_{22}\end{array} \right|= (-1)^0a_{11}a_{22}+(-1)^1a_{12}a_{21},
$$

<p>where in the last term we have interchanged the column indices \( 1 \) and \( 2 \). The natural ordering we have chosen is \( a_{11}a_{22} \). </p>

<p>The single-particle function \( \psi_{\alpha}(x_i) \)  are eigenfunctions of the onebody
Hamiltonian \( h_i \), that is
</p>
$$
\hat{h}_0(x_i)=\hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i),
$$

<p>with eigenvalues </p>
$$
\hat{h}_0(x_i) \psi_{\alpha}(x_i)=\left(\hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i)\right)\psi_{\alpha}(x_i)=\varepsilon_{\alpha}\psi_{\alpha}(x_i).
$$

<p>The energies \( \varepsilon_{\alpha} \) are the so-called non-interacting single-particle energies, or unperturbed energies. 
The total energy is in this case the sum over all  single-particle energies, if no two-body or more complicated
many-body interactions are present.
</p>

<p>Let us denote the ground state energy by \( E_0 \). According to the
variational principle we have
</p>
$$
  E_0 \le E[\Phi] = \int \Phi^*\hat{H}\Phi d\mathbf{\tau}
$$

<p>where \( \Phi \) is a trial function which we assume to be normalized</p>
$$
  \int \Phi^*\Phi d\mathbf{\tau} = 1,
$$

<p>where we have used the shorthand \( d\mathbf{\tau}=dx_1dr_2\dots dr_A \).</p>

<p>In the Hartree-Fock method the trial function is the Slater
determinant of Eq.&nbsp;\eqref{eq:HartreeFockDet} which can be rewritten as 
</p>
$$
  \Phi(x_1,x_2,\dots,x_N,\alpha,\beta,\dots,\nu) = \frac{1}{\sqrt{A!}}\sum_{P} (-)^P\hat{P}\psi_{\alpha}(x_1)
    \psi_{\beta}(x_2)\dots\psi_{\nu}(x_N)=\sqrt{N!}\hat{A}\Phi_H,
$$

<p>where we have introduced the antisymmetrization operator \( \hat{A} \) defined by the 
summation over all possible permutations of two particles.
</p>

<p>It is defined as</p>
$$
\begin{equation}
  \hat{A} = \frac{1}{N!}\sum_{p} (-)^p\hat{P},
\label{antiSymmetryOperator}
\end{equation}
$$

<p>with \( p \) standing for the number of permutations. We have introduced for later use the so-called
Hartree-function, defined by the simple product of all possible single-particle functions
</p>
$$
  \Phi_H(x_1,x_2,\dots,x_A,\alpha,\beta,\dots,\nu) =
  \psi_{\alpha}(x_1)
    \psi_{\beta}(x_2)\dots\psi_{\nu}(x_A).
$$

<p>Both \( \hat{H}_0 \) and \( \hat{H}_I \) are invariant under all possible permutations of any two particles
and hence commute with \( \hat{A} \)
</p>
$$
\begin{equation}
  [H_0,\hat{A}] = [H_I,\hat{A}] = 0. \label{commutionAntiSym}
\end{equation}
$$

<p>Furthermore, \( \hat{A} \) satisfies</p>
$$
\begin{equation}
  \hat{A}^2 = \hat{A},  \label{AntiSymSquared}
\end{equation}
$$

<p>since every permutation of the Slater
determinant reproduces it. 
</p>

<p>The expectation value of \( \hat{H}_0 \) </p>
$$
  \int \Phi^*\hat{H}_0\Phi d\mathbf{\tau} 
  = A! \int \Phi_H^*\hat{A}\hat{H}_0\hat{A}\Phi_H d\mathbf{\tau}
$$

<p>is readily reduced to</p>
$$
  \int \Phi^*\hat{H}_0\Phi d\mathbf{\tau} 
  = A! \int \Phi_H^*\hat{H}_0\hat{A}\Phi_H d\mathbf{\tau},
$$

<p>where we have used Eqs.&nbsp;\eqref{commutionAntiSym} and
\eqref{AntiSymSquared}. The next step is to replace the antisymmetrization
operator by its definition and to
replace \( \hat{H}_0 \) with the sum of one-body operators
</p>
$$
  \int \Phi^*\hat{H}_0\Phi  d\mathbf{\tau}
  = \sum_{i=1}^N \sum_{p} (-)^p\int 
  \Phi_H^*\hat{h}_0\hat{P}\Phi_H d\mathbf{\tau}.
$$

<p>The integral vanishes if two or more particles are permuted in only one
of the Hartree-functions \( \Phi_H \) because the individual single-particle wave functions are
orthogonal. We obtain then
</p>
$$
  \int \Phi^*\hat{H}_0\Phi  d\mathbf{\tau}= \sum_{i=1}^N \int \Phi_H^*\hat{h}_0\Phi_H  d\mathbf{\tau}.
$$

<p>Orthogonality of the single-particle functions allows us to further simplify the integral, and we
arrive at the following expression for the expectation values of the
sum of one-body Hamiltonians 
</p>
$$
\begin{equation}
  \int \Phi^*\hat{H}_0\Phi  d\mathbf{\tau}
  = \sum_{\mu=1}^N \int \psi_{\mu}^*(x)\hat{h}_0\psi_{\mu}(x)dx
  d\mathbf{r}.
\label{H1Expectation}
\end{equation}
$$

<p>We introduce the following shorthand for the above integral</p>
$$
\langle \mu | \hat{h}_0 | \mu \rangle = \int \psi_{\mu}^*(x)\hat{h}_0\psi_{\mu}(x)dx,
$$

<p>and rewrite Eq.&nbsp;\eqref{H1Expectation} as</p>
$$
\begin{equation}
  \int \Phi^*\hat{H}_0\Phi  d\tau
  = \sum_{\mu=1}^N \langle \mu | \hat{h}_0 | \mu \rangle.
\label{H1Expectation1}
\end{equation}
$$

<p>The expectation value of the two-body part of the Hamiltonian is obtained in a
similar manner. We have
</p>
$$
  \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = N! \int \Phi_H^*\hat{A}\hat{H}_I\hat{A}\Phi_H d\mathbf{\tau},
$$

<p>which reduces to</p>
$$
 \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = \sum_{i\le j=1}^N \sum_{p} (-)^p\int 
  \Phi_H^*\hat{v}(r_{ij})\hat{P}\Phi_H d\mathbf{\tau},
$$

<p>by following the same arguments as for the one-body
Hamiltonian. 
</p>

<p>Because of the dependence on the inter-particle distance \( r_{ij} \),  permutations of
any two particles no longer vanish, and we get
</p>
$$
  \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = \sum_{i < j=1}^N \int  
  \Phi_H^*\hat{v}(r_{ij})(1-P_{ij})\Phi_H d\mathbf{\tau}.
$$

<p>where \( P_{ij} \) is the permutation operator that interchanges
particle \( i \) and particle \( j \). Again we use the assumption that the single-particle wave functions
are orthogonal. 
</p>

<p>We obtain</p>
$$
\begin{align}
  \int \Phi^*\hat{H}_I\Phi d\mathbf{\tau} 
  = \frac{1}{2}\sum_{\mu=1}^N\sum_{\nu=1}^N
    &\left[ \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)\hat{v}(r_{ij})\psi_{\mu}(x_i)\psi_{\nu}(x_j)
    dx_idx_j \right.
\label{_auto2}\\
  &\left.
  - \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)
  \hat{v}(r_{ij})\psi_{\nu}(x_i)\psi_{\mu}(x_j)
  dx_idx_j
  \right]. \label{H2Expectation}
\end{align}
$$

<p>The first term is the so-called direct term. It is frequently also called the  Hartree term, 
while the second is due to the Pauli principle and is called
the exchange term or just the Fock term.
The factor  \( 1/2 \) is introduced because we now run over
all pairs twice. 
</p>

<p>The last equation allows us to  introduce some further definitions.  
The single-particle wave functions \( \psi_{\mu}(x) \), defined by the quantum numbers \( \mu \) and \( x \)
are defined as the overlap 
</p>
$$
   \psi_{\alpha}(x)  = \langle x | \alpha \rangle .
$$

<p>We introduce the following shorthands for the above two integrals</p>
$$
\langle \mu\nu|\hat{v}|\mu\nu\rangle =  \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)\hat{v}(r_{ij})\psi_{\mu}(x_i)\psi_{\nu}(x_j)
    dx_idx_j,
$$

<p>and</p>
$$
\langle \mu\nu|\hat{v}|\nu\mu\rangle = \int \psi_{\mu}^*(x_i)\psi_{\nu}^*(x_j)
  \hat{v}(r_{ij})\psi_{\nu}(x_i)\psi_{\mu}(x_j)
  dx_idx_j.  
$$
<h2 id="preparing-for-later-studies-varying-the-coefficients-of-a-wave-function-expansion-and-orthogonal-transformations">Preparing for later studies: varying the coefficients of a wave function expansion and orthogonal transformations </h2>

<p>It is common to  expand the single-particle functions in a known basis  and vary the coefficients, 
that is, the new single-particle wave function is written as a linear expansion
in terms of a fixed chosen orthogonal basis (for example the well-known harmonic oscillator functions or the hydrogen-like functions etc).
We define our new single-particle basis (this is a normal approach for Hartree-Fock theory) by performing a unitary transformation 
on our previous basis (labelled with greek indices) as
</p>
$$
\begin{equation}
\psi_p^{new}  = \sum_{\lambda} C_{p\lambda}\phi_{\lambda}. \label{eq:newbasis}
\end{equation}
$$

<p>In this case we vary the coefficients \( C_{p\lambda} \). If the basis has infinitely many solutions, we need
to truncate the above sum.  We assume that the basis \( \phi_{\lambda} \) is orthogonal.
</p>

<p>It is normal to choose a single-particle basis defined as the eigenfunctions
of parts of the full Hamiltonian. The typical situation consists of the solutions of the one-body part of the Hamiltonian, that is we have
</p>
$$
\hat{h}_0\phi_{\lambda}=\epsilon_{\lambda}\phi_{\lambda}.
$$

<p>The single-particle wave functions \( \phi_{\lambda}(\mathbf{r}) \), defined by the quantum numbers \( \lambda \) and \( \mathbf{r} \)
are defined as the overlap 
</p>
$$
   \phi_{\lambda}(\mathbf{r})  = \langle \mathbf{r} | \lambda \rangle .
$$

<p>In deriving the Hartree-Fock equations, we  will expand the single-particle functions in a known basis  and vary the coefficients, 
that is, the new single-particle wave function is written as a linear expansion
in terms of a fixed chosen orthogonal basis (for example the well-known harmonic oscillator functions or the hydrogen-like functions etc).
</p>

<p>We stated that a unitary transformation keeps the orthogonality. To see this consider first a basis of vectors \( \mathbf{v}_i \),</p>
$$
\mathbf{v}_i = \begin{bmatrix} v_{i1} \\ \dots \\ \dots \\v_{in} \end{bmatrix}
$$

<p>We assume that the basis is orthogonal, that is </p>
$$
\mathbf{v}_j^T\mathbf{v}_i = \delta_{ij}.
$$

<p>An orthogonal or unitary transformation</p>
$$
\mathbf{w}_i=\mathbf{U}\mathbf{v}_i,
$$

<p>preserves the dot product and orthogonality since</p>
$$
\mathbf{w}_j^T\mathbf{w}_i=(\mathbf{U}\mathbf{v}_j)^T\mathbf{U}\mathbf{v}_i=\mathbf{v}_j^T\mathbf{U}^T\mathbf{U}\mathbf{v}_i= \mathbf{v}_j^T\mathbf{v}_i = \delta_{ij}.
$$

<p>This means that if the coefficients \( C_{p\lambda} \) belong to a unitary or orthogonal trasformation (using the Dirac bra-ket notation)</p>
$$
\vert p\rangle  = \sum_{\lambda} C_{p\lambda}\vert\lambda\rangle,
$$

<p>orthogonality is preserved, that is \( \langle \alpha \vert \beta\rangle = \delta_{\alpha\beta} \)
and \( \langle p \vert q\rangle = \delta_{pq} \). 
</p>

<p>This propertry is extremely useful when we build up a basis of many-body Stater determinant based states. </p>

<b>Note also that although a basis \( \vert \alpha\rangle \) contains an infinity of states, for practical calculations we have always to make some truncations.</b>

<p>Before we develop for example the Hartree-Fock equations, there is another very useful property of determinants that we will use both in connection with Hartree-Fock calculations and later shell-model calculations.  </p>

<p>Consider the following determinant</p>
$$
\left| \begin{array}{cc} \alpha_1b_{11}+\alpha_2sb_{12}& a_{12}\\
                         \alpha_1b_{21}+\alpha_2b_{22}&a_{22}\end{array} \right|=\alpha_1\left|\begin{array}{cc} b_{11}& a_{12}\\
                         b_{21}&a_{22}\end{array} \right|+\alpha_2\left| \begin{array}{cc} b_{12}& a_{12}\\b_{22}&a_{22}\end{array} \right|
$$

<p>We can generalize this to  an \( n\times n \) matrix and have </p>
$$
\left| \begin{array}{cccccc} a_{11}& a_{12} & \dots & \sum_{k=1}^n c_k b_{1k} &\dots & a_{1n}\\
a_{21}& a_{22} & \dots & \sum_{k=1}^n c_k b_{2k} &\dots & a_{2n}\\
\dots & \dots & \dots & \dots & \dots & \dots \\
\dots & \dots & \dots & \dots & \dots & \dots \\
a_{n1}& a_{n2} & \dots & \sum_{k=1}^n c_k b_{nk} &\dots & a_{nn}\end{array} \right|=
\sum_{k=1}^n c_k\left| \begin{array}{cccccc} a_{11}& a_{12} & \dots &  b_{1k} &\dots & a_{1n}\\
a_{21}& a_{22} & \dots &  b_{2k} &\dots & a_{2n}\\
\dots & \dots & \dots & \dots & \dots & \dots\\
\dots & \dots & \dots & \dots & \dots & \dots\\
a_{n1}& a_{n2} & \dots &  b_{nk} &\dots & a_{nn}\end{array} \right| .
$$

<p>This is a property we will use in our Hartree-Fock discussions. </p>

<p>We can generalize the previous results, now 
with all elements \( a_{ij} \)  being given as functions of 
linear combinations  of various coefficients \( c \) and elements \( b_{ij} \),
</p>
$$
\left| \begin{array}{cccccc} \sum_{k=1}^n b_{1k}c_{k1}& \sum_{k=1}^n b_{1k}c_{k2} & \dots & \sum_{k=1}^n b_{1k}c_{kj}  &\dots & \sum_{k=1}^n b_{1k}c_{kn}\\
\sum_{k=1}^n b_{2k}c_{k1}& \sum_{k=1}^n b_{2k}c_{k2} & \dots & \sum_{k=1}^n b_{2k}c_{kj} &\dots & \sum_{k=1}^n b_{2k}c_{kn}\\
\dots & \dots & \dots & \dots & \dots & \dots \\
\dots & \dots & \dots & \dots & \dots &\dots \\
\sum_{k=1}^n b_{nk}c_{k1}& \sum_{k=1}^n b_{nk}c_{k2} & \dots & \sum_{k=1}^n b_{nk}c_{kj} &\dots & \sum_{k=1}^n b_{nk}c_{kn}\end{array} \right|=det(\mathbf{C})det(\mathbf{B}),
$$

<p>where \( det(\mathbf{C}) \) and \( det(\mathbf{B}) \) are the determinants of \( n\times n \) matrices
with elements \( c_{ij} \) and \( b_{ij} \) respectively.  
This is a property we will use in our Hartree-Fock discussions. Convince yourself about the correctness of the above expression by setting \( n=2 \). 
</p>

<p>With our definition of the new basis in terms of an orthogonal basis we have</p>
$$
\psi_p(x)  = \sum_{\lambda} C_{p\lambda}\phi_{\lambda}(x).
$$

<p>If the coefficients \( C_{p\lambda} \) belong to an orthogonal or unitary matrix, the new basis
is also orthogonal. 
Our Slater determinant in the new basis \( \psi_p(x) \) is written as
</p>
$$
\frac{1}{\sqrt{A!}}
\left| \begin{array}{ccccc} \psi_{p}(x_1)& \psi_{p}(x_2)& \dots & \dots & \psi_{p}(x_A)\\
                            \psi_{q}(x_1)&\psi_{q}(x_2)& \dots & \dots & \psi_{q}(x_A)\\  
                            \dots & \dots & \dots & \dots & \dots \\
                            \dots & \dots & \dots & \dots & \dots \\
                     \psi_{t}(x_1)&\psi_{t}(x_2)& \dots & \dots & \psi_{t}(x_A)\end{array} \right|=\frac{1}{\sqrt{A!}}
\left| \begin{array}{ccccc} \sum_{\lambda} C_{p\lambda}\phi_{\lambda}(x_1)& \sum_{\lambda} C_{p\lambda}\phi_{\lambda}(x_2)& \dots & \dots & \sum_{\lambda} C_{p\lambda}\phi_{\lambda}(x_A)\\
                            \sum_{\lambda} C_{q\lambda}\phi_{\lambda}(x_1)&\sum_{\lambda} C_{q\lambda}\phi_{\lambda}(x_2)& \dots & \dots & \sum_{\lambda} C_{q\lambda}\phi_{\lambda}(x_A)\\  
                            \dots & \dots & \dots & \dots & \dots \\
                            \dots & \dots & \dots & \dots & \dots \\
                     \sum_{\lambda} C_{t\lambda}\phi_{\lambda}(x_1)&\sum_{\lambda} C_{t\lambda}\phi_{\lambda}(x_2)& \dots & \dots & \sum_{\lambda} C_{t\lambda}\phi_{\lambda}(x_A)\end{array} \right|,
$$

<p>which is nothing but \( det(\mathbf{C})det(\Phi) \), with \( det(\Phi) \) being the determinant given by the basis functions \( \phi_{\lambda}(x) \). </p>

<p>In our discussions hereafter we will use our definitions of single-particle states above and below the Fermi (\( F \)) level given by the labels
\( ijkl\dots \le F \) for so-called single-hole states and \( abcd\dots > F \) for so-called particle states.
For general single-particle states we employ the labels \( pqrs\dots \). 
</p>

<p>The energy functional is</p>
$$
  E[\Phi] 
  = \sum_{\mu=1}^N \langle \mu | h | \mu \rangle +
  \frac{1}{2}\sum_{{\mu}=1}^N\sum_{{\nu}=1}^N \langle \mu\nu|\hat{v}|\mu\nu\rangle_{AS},
$$

<p>we found the expression for the energy functional in terms of the basis function \( \phi_{\lambda}(\mathbf{r}) \). We then  varied the above energy functional with respect to the basis functions \( |\mu \rangle \). 
Now we are interested in defining a new basis defined in terms of
a chosen basis as defined in Eq.&nbsp;\eqref{eq:newbasis}. We can then rewrite the energy functional as
</p>
$$
\begin{equation}
  E[\Phi^{New}] 
  = \sum_{i=1}^N \langle i | h | i \rangle +
  \frac{1}{2}\sum_{ij=1}^N\langle ij|\hat{v}|ij\rangle_{AS}, \label{FunctionalEPhi2}
\end{equation}
$$

<p>where \( \Phi^{New} \) is the new Slater determinant defined by the new basis of Eq.&nbsp;\eqref{eq:newbasis}. </p>

<p>Using Eq.&nbsp;\eqref{eq:newbasis} we can rewrite Eq.&nbsp;\eqref{FunctionalEPhi2} as </p>
$$
\begin{equation}
  E[\Psi] 
  = \sum_{i=1}^N \sum_{\alpha\beta} C^*_{i\alpha}C_{i\beta}\langle \alpha | h | \beta \rangle +
  \frac{1}{2}\sum_{ij=1}^N\sum_{{\alpha\beta\gamma\delta}} C^*_{i\alpha}C^*_{j\beta}C_{i\gamma}C_{j\delta}\langle \alpha\beta|\hat{v}|\gamma\delta\rangle_{AS}. \label{FunctionalEPhi3}
\end{equation}
$$


<!-- ------------------- end of main content --------------- -->
<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2023, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license
</center>
</body>
</html>

