<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week11.do.txt --pygments_html_style=perldoc --html_style=solarized3 --html_links_in_new_window --html_output=week11-solarized --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="April 17-21, 2023: Quantum Computing, Quantum Machine Learning and Quantum Information Theories">
<title>April 17-21, 2023: Quantum Computing, Quantum Machine Learning and Quantum Information Theories</title>
<link href="https://cdn.rawgit.com/doconce/doconce/master/bundled/html_styles/style_solarized_box/css/solarized_light_code.css" rel="stylesheet" type="text/css" title="light"/>
<script src="https://cdn.rawgit.com/doconce/doconce/master/bundled/html_styles/style_solarized_box/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<link href="https://thomasf.github.io/solarized-css/solarized-light.min.css" rel="stylesheet">
<style type="text/css">
h1 {color: #b58900;}  /* yellow */
/* h1 {color: #cb4b16;}  orange */
/* h1 {color: #d33682;}  magenta, the original choice of thomasf */
code { padding: 0px; background-color: inherit; }
pre {
  border: 0pt solid #93a1a1;
  box-shadow: none;
}
.alert-text-small   { font-size: 80%;  }
.alert-text-large   { font-size: 130%; }
.alert-text-normal  { font-size: 90%;  }
.alert {
  padding:8px 35px 8px 14px; margin-bottom:18px;
  text-shadow:0 1px 0 rgba(255,255,255,0.5);
  border:1px solid #93a1a1;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  -moz-border-radius: 4px;
  color: #555;
  background-color: #eee8d5;
  background-position: 10px 5px;
  background-repeat: no-repeat;
  background-size: 38px;
  padding-left: 55px;
  width: 75%;
 }
.alert-block {padding-top:14px; padding-bottom:14px}
.alert-block > p, .alert-block > ul {margin-bottom:1em}
.alert li {margin-top: 1em}
.alert-block p+p {margin-top:5px}
.alert-notice { background-image: url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_yellow_notice.png); }
.alert-summary  { background-image:url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_yellow_summary.png); }
.alert-warning { background-image: url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_yellow_warning.png); }
.alert-question {background-image:url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_yellow_question.png); }
div { text-align: justify; text-justify: inter-word; }
.tab {
  padding-left: 1.5em;
}
div.toc p,a {
  line-height: 1.3;
  margin-top: 1.1;
  margin-bottom: 1.1;
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plans for the week of April 17-21',
               2,
               None,
               'plans-for-the-week-of-april-17-21'),
              ('VQE and efficient computations of gradients',
               2,
               None,
               'vqe-and-efficient-computations-of-gradients'),
              ('Setting up the matrix', 2, None, 'setting-up-the-matrix'),
              ('Implementing the VQE', 2, None, 'implementing-the-vqe'),
              ('Gradient descent and calculations of gradients',
               2,
               None,
               'gradient-descent-and-calculations-of-gradients'),
              ('Basics of gradient descent and stochastic gradient descent',
               3,
               None,
               'basics-of-gradient-descent-and-stochastic-gradient-descent'),
              ('Computing quantum gradients in a smarter way',
               3,
               None,
               'computing-quantum-gradients-in-a-smarter-way'),
              ('A smarter way of doing this',
               2,
               None,
               'a-smarter-way-of-doing-this'),
              ('Two-qubit system and the VQE',
               2,
               None,
               'two-qubit-system-and-the-vqe')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "AMS"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- ------------------- main content ---------------------- -->
<center>
<h1>April 17-21, 2023: Quantum Computing, Quantum Machine Learning and Quantum Information Theories</h1>
</center>  <!-- document title -->

<!-- author(s): Morten Hjorth-Jensen -->
<center>
<b>Morten Hjorth-Jensen</b> [1, 2]
</center>
<!-- institution(s) -->
<center>
[1] <b>Department of Physics, University of Oslo</b>
</center>
<center>
[2] <b>Department of Physics and Astronomy and Facility for Rare Isotope Beams, Michigan State University</b>
</center>
<br>
<center>
<h4>Apr 4, 2023</h4>
</center> <!-- date -->
<br>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="plans-for-the-week-of-april-17-21">Plans for the week of April 17-21 </h2>

<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<ol>
 <li> Reminder on basics of the VQE method</li>
 <li> Simulating efficiently Hamiltonians on quantum computers with the VQE method
<ol type="a"></li>
   <li> Discussions of various gradient descent approaches</li>
</ol>
 <li> <a href="https://www.sciencedirect.com/science/article/pii/S0370157322003118?via%3Dihub" target="_blank">VQE review article</a></li>
 <li> <a href="https://youtu.be/" target="_blank">Video of lecture TBA</a></li>
</ol>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="vqe-and-efficient-computations-of-gradients">VQE and efficient computations of gradients  </h2>

<p>We start with a reminder on the VQE method with applications to the one-qubit system.
We discussed this to some detail during the week of March 27-31. Here we revisit the one-qubit system and develop a VQE code for studying this system using gradient descent as a method to optimie the variational ansatz.
</p>

<p>We start with a simple \( 2\times 2 \) Hamiltonian matrix expressed in
terms of Pauli \( X \) and \( Z \) matrices, as discussed in the project text.
</p>

<p>We define a  symmetric matrix  \( H\in {\mathbb{R}}^{2\times 2} \)</p>
$$
H = \begin{bmatrix} H_{11} & H_{12} \\ H_{21} & H_{22}
\end{bmatrix},
$$

<p>We  let \( H = H_0 + H_I \), where</p>
$$
H_0= \begin{bmatrix} E_1 & 0 \\ 0 & E_2\end{bmatrix},
$$

<p>is a diagonal matrix. Similarly,</p>
$$
H_I= \begin{bmatrix} V_{11} & V_{12} \\ V_{21} & V_{22}\end{bmatrix},
$$

<p>where \( V_{ij} \) represent various interaction matrix elements.
We can view \( H_0 \) as the non-interacting solution
</p>
$$
\begin{equation}
       H_0\vert 0 \rangle =E_1\vert 0 \rangle,
\label{_auto1}
\end{equation}
$$

<p>and</p>
$$
\begin{equation}
       H_0\vert 1\rangle =E_2\vert 1\rangle,
\label{_auto2}
\end{equation}
$$

<p>where we have defined the orthogonal computational one-qubit basis states \( \vert 0\rangle \) and \( \vert 1\rangle \).</p>

<p>We rewrite \( H \) (and \( H_0 \) and \( H_I \))  via Pauli matrices</p>
$$
H_0 = \mathcal{E} I + \Omega \sigma_z, \quad \mathcal{E} = \frac{E_1
  + E_2}{2}, \; \Omega = \frac{E_1-E_2}{2},
$$

<p>and</p>
$$
H_I = c \boldsymbol{I} +\omega_z\sigma_z + \omega_x\sigma_x,
$$

<p>with \( c = (V_{11}+V_{22})/2 \), \( \omega_z = (V_{11}-V_{22})/2 \) and \( \omega_x = V_{12}=V_{21} \).
We let our Hamiltonian depend linearly on a strength parameter \( \lambda \)
</p>

$$
H=H_0+\lambda H_\mathrm{I},
$$

<p>with \( \lambda \in [0,1] \), where the limits \( \lambda=0 \) and \( \lambda=1 \)
represent the non-interacting (or unperturbed) and fully interacting
system, respectively.  The model is an eigenvalue problem with only
two available states.
</p>

<p>Here we set the parameters \( E_1=0 \),
\( E_2=4 \), \( V_{11}=-V_{22}=3 \) and \( V_{12}=V_{21}=0.2 \).
</p>

<p>The non-interacting solutions represent our computational basis.
Pertinent to our choice of parameters, is that at \( \lambda\geq 2/3 \),
the lowest eigenstate is dominated by \( \vert 1\rangle \) while the upper
is \( \vert 0 \rangle \). At \( \lambda=1 \) the \( \vert 0 \rangle \) mixing of
the lowest eigenvalue is \( 1\% \) while for \( \lambda\leq 2/3 \) we have a
\( \vert 0 \rangle \) component of more than \( 90\% \).  The character of the
eigenvectors has therefore been interchanged when passing \( z=2/3 \). The
value of the parameter \( V_{12} \) represents the strength of the coupling
between the two states.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="setting-up-the-matrix">Setting up the matrix </h2>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="line-height: 125%;"><span style="color: #8B008B; font-weight: bold">from</span>  <span style="color: #008b45; text-decoration: underline">matplotlib</span> <span style="color: #8B008B; font-weight: bold">import</span> pyplot <span style="color: #8B008B; font-weight: bold">as</span> plt
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">np</span>
dim = <span style="color: #B452CD">2</span>
Hamiltonian = np.zeros((dim,dim))
e0 = <span style="color: #B452CD">0.0</span>
e1 = <span style="color: #B452CD">4.0</span>
Xnondiag = <span style="color: #B452CD">0.20</span>
Xdiag = <span style="color: #B452CD">3.0</span>
Eigenvalue = np.zeros(dim)
<span style="color: #228B22"># setting up the Hamiltonian</span>
Hamiltonian[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">0</span>] = Xdiag+e0
Hamiltonian[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>] = Xnondiag
Hamiltonian[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>] = Hamiltonian[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]
Hamiltonian[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>] = e1-Xdiag
<span style="color: #228B22"># diagonalize and obtain eigenvalues, not necessarily sorted</span>
EigValues, EigVectors = np.linalg.eig(Hamiltonian)
permute = EigValues.argsort()
EigValues = EigValues[permute]
<span style="color: #228B22"># print only the lowest eigenvalue</span>
<span style="color: #658b00">print</span>(EigValues[<span style="color: #B452CD">0</span>])
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>Now rewrite it in terms of the identity matrix and the Pauli matrix X and Z</p>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="line-height: 125%;"><span style="color: #228B22"># Now rewrite it in terms of the identity matrix and the Pauli matrix X and Z</span>
X = np.array([[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>],[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>]])
Y = np.array([[<span style="color: #B452CD">0</span>,-<span style="color: #B452CD">1</span>j],[<span style="color: #B452CD">1</span>j,<span style="color: #B452CD">0</span>]])
Z = np.array([[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>],[<span style="color: #B452CD">0</span>,-<span style="color: #B452CD">1</span>]])
<span style="color: #228B22"># identity matrix</span>
I = np.array([[<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>],[<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>]])

epsilon = (e0+e1)*<span style="color: #B452CD">0.5</span>; omega = (e0-e1)*<span style="color: #B452CD">0.5</span>
c = <span style="color: #B452CD">0.0</span>; omega_z=Xdiag; omega_x = Xnondiag
Hamiltonian = (epsilon+c)*I+(omega_z+omega)*Z+omega_x*X
EigValues, EigVectors = np.linalg.eig(Hamiltonian)
permute = EigValues.argsort()
EigValues = EigValues[permute]
<span style="color: #228B22"># print only the lowest eigenvalue</span>
<span style="color: #658b00">print</span>(EigValues[<span style="color: #B452CD">0</span>])
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="implementing-the-vqe">Implementing the VQE </h2>

<p>For a one-qubit system we can reach every point on the Bloch sphere
(as discussed earlier) with a rotation about the \( x \)-axis and the
\( y \)-axis.
</p>

<p>We can express this mathematically through the following operations (see whiteboard for the drawing), giving us a new state \( \vert \psi\rangle \)</p>
$$
\vert\psi\rangle = R_y(\phi)R_x(\theta)\vert 0 \rangle.
$$

<p>We can produce multiple ansatzes for the new state in terms of the
angles \( \theta \) and \( \phi \).  With these ansatzes we can in turn
calculate the expectation value of the above Hamiltonian, now
rewritten in terms of various Pauli matrices (and thereby gates), that is compute
</p>

$$
\langle \psi \vert (c+\mathcal{E})\boldsymbol{I} + (\Omega+\omega_z)\boldsymbol{\sigma}_z + \omega_x\boldsymbol{\sigma}_x\vert \psi \rangle.
$$

<p>We can now set up a series of ansatzes for \( \vert \psi \rangle \) as
function of the angles \( \theta \) and \( \phi \) and find thereafter the
variational minimum using for example a gradient descent method.
</p>

<p>To do so, we need to remind ourselves about the mathematical expressions for
the rotational matrices/operators.
</p>

$$
R_x(\theta)=\cos{\frac{\theta}{2}}\boldsymbol{I}-\imath \sin{\frac{\theta}{2}}\boldsymbol{\sigma}_x,
$$

<p>and</p>

$$
R_y(\phi)=\cos{\frac{\phi}{2}}\boldsymbol{I}-\imath \sin{\frac{\phi}{2}}\boldsymbol{\sigma}_y.
$$



<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="line-height: 125%;"><span style="color: #228B22"># define the rotation matrices</span>
<span style="color: #228B22"># Define angles theta and phi</span>
theta = <span style="color: #B452CD">0.5</span>*np.pi; phi = <span style="color: #B452CD">0.2</span>*np.pi
Rx = np.cos(theta*<span style="color: #B452CD">0.5</span>)*I-<span style="color: #B452CD">1</span>j*np.sin(theta*<span style="color: #B452CD">0.5</span>)*X
Ry = np.cos(phi*<span style="color: #B452CD">0.5</span>)*I-<span style="color: #B452CD">1</span>j*np.sin(phi*<span style="color: #B452CD">0.5</span>)*Y
<span style="color: #228B22">#define basis states</span>
basis0 = np.array([<span style="color: #B452CD">1</span>,<span style="color: #B452CD">0</span>])
basis1 = np.array([<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>])

NewBasis = Ry @ Rx @ basis0
<span style="color: #658b00">print</span>(NewBasis)
<span style="color: #228B22"># Compute the expectation value</span>
<span style="color: #228B22">#Note hermitian conjugation</span>
Energy = NewBasis.conj().T @ Hamiltonian @ NewBasis
<span style="color: #658b00">print</span>(Energy)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>Not an impressive results. We set up now a loop over many angles \( \theta \) and \( \phi \) and compute the energies</p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="line-height: 125%;"><span style="color: #228B22"># define a number of angles</span>
n = <span style="color: #B452CD">20</span>
angle = np.arange(<span style="color: #B452CD">0</span>,<span style="color: #B452CD">180</span>,<span style="color: #B452CD">10</span>)
n = np.size(angle)
ExpectationValues = np.zeros((n,n))
<span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span> (n):
    theta = np.pi*angle[i]/<span style="color: #B452CD">180.0</span>
    Rx = np.cos(theta*<span style="color: #B452CD">0.5</span>)*I-<span style="color: #B452CD">1</span>j*np.sin(theta*<span style="color: #B452CD">0.5</span>)*X
    <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span> (n):
        phi = np.pi*angle[j]/<span style="color: #B452CD">180.0</span>
        Ry = np.cos(phi*<span style="color: #B452CD">0.5</span>)*I-<span style="color: #B452CD">1</span>j*np.sin(phi*<span style="color: #B452CD">0.5</span>)*Y
        NewBasis = Ry @ Rx @ basis0
        Energy = NewBasis.conj().T @ Hamiltonian @ NewBasis
        Edifference=<span style="color: #658b00">abs</span>(np.real(EigValues[<span style="color: #B452CD">0</span>]-Energy))
        ExpectationValues[i,j]=Edifference

<span style="color: #658b00">print</span>(np.min(ExpectationValues))
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>Clearly, this is not the very best way of proceeding. Rather, here we
could try to find the optimal values for the parameters \( \theta \) and \( \phi \) through computation of their respective  gradients and thereby find the minimum as function of
the optimal angles \( \hat{\theta} \) and \( \hat{\phi} \). 
</p>

<p>Let us now implement a classical gradient descent to the computation of the energies. 
We will follow closely  <a href="https://journals.aps.org/pra/abstract/10.1103/PhysRevA.99.032331" target="_blank"><tt>https://journals.aps.org/pra/abstract/10.1103/PhysRevA.99.032331</tt></a> in order to calculate gradients of the Hamiltonian.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="gradient-descent-and-calculations-of-gradients">Gradient descent and calculations of gradients </h2>

<p>In order to optimize the VQE ansatz, we need to compute derivatives
with respect to the variational parameters.  Here we develop first a
simpler approach tailored to the one-qubit case. For this particular
case, we have defined an ansatz in terms of the Pauli rotation
matrices. These define an arbitrary one-qubit state on the Bloch
sphere through the expression
</p>

$$
\vert\psi\rangle = \vert \psi(\theta,\phi)\rangle =R_y(\phi)R_x(\theta)\vert 0 \rangle.
$$

<p>Each of these rotation matrices can be written in a more general form as</p>
$$
R_{i}(\gamma)=\exp{-(\imath\frac{\gamma}{2}\sigma_i)}=\cos{(\frac{\gamma}{2})}\boldsymbol{I}-\imath\sin{(\frac{\gamma}{2})}\boldsymbol{\sigma}_i,
$$

<p>where \( \sigma_i \) is one of the Pauli matrices \( \sigma_{x,y,z} \). </p>

<p>It is easy to see that the derivative with respect to \( \gamma \) is</p>
$$
\frac{\partial R_{i}(\gamma)}{\partial \gamma}=-\frac{\gamma}{2}\boldsymbol{\sigma}_i R_{i}(\gamma).
$$

<p>We can now calculate the derivative of the expectation value of the
Hamiltonian in terms of the angles \( \theta \) and \( \phi \). We have two
derivatives 
</p>
$$
\frac{\partial}{\partial \theta}\left[\langle \psi(\theta,\phi) \vert \boldsymbol{H}\vert \psi(\theta,\phi)\rangle\right]=\langle \psi(\theta,\phi) \vert \boldsymbol{H}(-\frac{\imath}{2}\boldsymbol{\sigma}_x\vert \psi(\theta,\phi)\rangle+\hspace{0.1cm}\mathrm{h.c},
$$

<p>and</p>
$$
\frac{\partial }{\partial \phi}\left[\langle \psi(\theta,\phi) \vert \boldsymbol{H}\vert \psi(\theta,\phi)\rangle\right]=\langle \psi(\theta,\phi) \vert \boldsymbol{H}(-\frac{\imath}{2}\boldsymbol{\sigma}_y\vert \psi(\theta,\phi)\rangle+\hspace{0.1cm}\mathrm{h.c}. 
$$

<p>This means that we have to calculate two additional expectation values
in addition to the standard expectation value for the Hamiltonian.  In
our first attempt, we will compute these expectation values
in a brute force way, perforaming the various matrix-matrix and
matrix-vector multiplications. Thereafter we will try to rewrite this in a smarter way.
</p>
<h3 id="basics-of-gradient-descent-and-stochastic-gradient-descent">Basics of gradient descent and stochastic gradient descent </h3>
<h3 id="computing-quantum-gradients-in-a-smarter-way">Computing quantum gradients in a smarter way </h3>

$$
\begin{equation}
\vc(\theta) \coloneqq \expval{\hat{B}} = \bra{0} U^{\dagger}(\theta) \hat{B} U(\theta) \ket{0}.
\label{_auto3}
\end{equation}
$$


$$
\begin{equation}
    \quad \qquad \nabla \func(x) \approx (\func(x +\Delta x/2) -\func(x -\Delta x/2) )/\Delta x,
\label{_auto4}
\end{equation}
$$


$$
\begin{equation}
  \label{Eq:der_of_exp}
  \partial_\mu \vc = \partial_{\mu} \bra{\psi} \G^{\dagger} \hat{Q} \G\ket{\psi}
  = \bra{\psi} \G^{\dagger}  \hat{Q}  (\partial_{\mu}\G) \ket{\psi} +\hc,
\end{equation}
$$

$$
\begin{align}
  \bra{\psi}B^{\dagger} \hat{Q} C  \ket{\psi} +\hc\notag
\label{_auto5}\\
  \begin{split}
    = \frac{1}{2}\big(&
    \bra{\psi} (B + C)^{\dagger} \hat{Q} (B + C) \ket{\psi}
\label{_auto6}\\
    -&\bra{\psi}(B - C)^{\dagger}  \hat{Q} (B - C) \ket{\psi}
  \big).
\end{split}
\label{_auto7}
\end{align}
$$


$$
\begin{equation}
 \partial_{\mu} \G = -i G \e^{-i \mu G}.
\label{_auto8}
\end{equation}
$$


$$
\begin{align}
  \partial_{\mu} \vc
%  &= \bra{\psi} \G^{\dagger} \, \hat{Q} \, (-iG) \G \ket{\psi} +\hc ,
\label{_auto9}\\
%  &= r \bra{\psi'}  \hat{Q} \, (-ir^{-1}G) \ket{\psi'} +\hc
   &= \bra{\psi'}  \hat{Q} \, (-iG) \ket{\psi'} +\hc ,
\label{_auto10}
\end{align}
$$

$$
\begin{equation}
  \begin{split}
    \partial_{\mu} \vc = \frac{r}{2}\big(
    &\bra{\psi'} (\I -ir^{-1}G)^{\dagger} \hat{Q} (\I -ir^{-1}G) \ket{\psi'}\\
    -&\bra{\psi'}(\I +ir^{-1}G)^{\dagger}  \hat{Q} (\I +ir^{-1}G) \ket{\psi'}
    \big).
  \end{split}
\label{_auto11}
\end{equation}
$$


$$
\begin{equation}
  \G\left(\frac{\pi}{4r}\right) = \frac{1}{\sqrt{2}}(\I - i r^{-1} G).
\label{_auto12}
\end{equation}
$$


$$
\begin{align}
\partial_{\mu} \vc
&=
r \big(\bra{\psi} \G^\dagger(\mu +s) \hat{Q} \G(\mu +s) \ket{\psi}
\label{_auto13}\\
\notag
& \quad -\bra{\psi} \G^{\dagger}(\mu -s) \hat{Q}  \G(\mu -s) \ket{\psi}\big)
\label{_auto14}\\
\label{eq:parameter_shift_rule2}
&= r \left(f(\mu+s) -f(\mu-s)\right).
\end{align}
$$

$$
\begin{align*}
  \text{ExpW}(\mu, \delta) &= \exp \left(- i \mu \left( \cos (\delta) \sigma_x + \sin(\delta)\sigma_y\right) \right),\\
  \text{ExpZ}(\mu) &= \exp \left(- i \mu \sigma_z \right),\\
  \text{Exp11}(\mu) &= \exp \left(- i \mu \ketbra{11}{11}  \right) .
\end{align*}
$$


$$
\begin{equation}
  \partial_{\mu}\G = \frac{\alpha}{2} ((A_1 + A_1^{\dagger})  + i(A_2 + A_2^{\dagger}))
\label{_auto15}
\end{equation}
$$

<p>with real \( \alpha \).\footnote{
  If \( \alpha \) contains a renormalisation so that \( |\G| \leq 1 \), and
  \( \G = \G_{\mathrm{re}} + i \G_{\mathrm{im}} \) we can set
  \( A_1 = \G_{\mathrm{re}} + i \sqrt{\I - \G_{\mathrm{re}}^2} \) and
  \( A_2 = \G_{\mathrm{im}} + i \sqrt{\I - \G_{\mathrm{im}}^2} \).}
\( A_1 \) and \( A_2 \) in turn can be implemented as quantum circuits.
</p>
$$
\begin{equation}
  \partial_{\mu}\G = \sum_{k=1}^K \alpha_k A_k,
\label{_auto16}
\end{equation}
$$

<p>for real \( \alpha_k \) and unitary \( A_k \). The derivative becomes</p>
$$
\begin{equation}
  \partial_{\mu} \vc  = \sum_{k=1}^K \alpha_k  \left( \bra{\psi}\G^{\dagger} \hat{Q} A_k  \ket{\psi} +\hc \right).
\label{_auto17}
\end{equation}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="a-smarter-way-of-doing-this">A smarter way of doing this </h2>

<p>The above approach means that we are setting up several matrix-matrix
amd matrix-vector multiplications. Although straight forward it is not
the most efficient way of doing this, in particular in case the
matrices become large (and sparse). But there are some more important
issues.
</p>

<p>In a physical realization of these systems we cannot just multiply the
state with the Hamiltonian. When performing a measurement we can only
measure in one particular direction. For the computational basis
states which we have, \( \vert 0\rangle \) and \( \vert 1\rangle \), we have
to measure along the bases of the Pauli matrices and reconstruct the
eigenvalues from these measurements.
</p>

<p>From our earlier discussions we know that the Pauli \( Z \) matrix has the above basis states as eigen states through</p>

$$
\boldsymbol{\sigma}_z\vert 0 \rangle = \boldsymbol{Z}\vert 0 \rangle=+1\vert 0 \rangle,
$$

<p>and</p>
$$
\boldsymbol{\sigma}_z\vert 1 \rangle = \boldsymbol{Z}\vert 1 \rangle=-1\vert 1 \rangle,
$$

<p>with eigenvalue \( -1 \).</p>

<p>For the Pauli \( X \) matrix on the other hand we have</p>
$$
\boldsymbol{\sigma}_x\vert 0 \rangle = \boldsymbol{X}\vert 0 \rangle=+1\vert 1 \rangle,
$$

<p>and</p>
$$
\boldsymbol{\sigma}_x\vert 1 \rangle = \boldsymbol{X}\vert 1 \rangle=-1\vert 0 \rangle,
$$

<p>with eigenvalues \( 1 \) in both cases. The latter two equations tell us
that the computational basis we have chosen, and in which we will
prepare our states, is not an eigenbasis of the \( \sigma_x \) matrix.
</p>

<p>We will thus try to rewrite the Pauli \( X \) matrix in terms of a Pauli \( Z \) matrix. Fortunately this can be done using the Hadamard matrix twice, that is</p>

$$
\boldsymbol{X}=\boldsymbol{\sigma}_x=\boldsymbol{H}\boldsymbol{Z}\boldsymbol{H}.
$$

<p>The Pauli \( Y \) matrix can be written as</p>

$$
\boldsymbol{Y}=\boldsymbol{\sigma}_y=\boldsymbol{H}\boldsymbol{S}^{\dagger}\boldsymbol{Z}\boldsymbol{H}\boldsymbol{S},
$$

<p>where \( S \) is the phase matrix</p>
$$
S = \begin{bmatrix} 1 & 0 \\ 0 & \imath \end{bmatrix}.
$$

<p>From here and on we will denote the Pauli matrices by \( X \), \( Y \) and \( Z \) and we can write the expectation value of the Hamiltonian as</p>
$$
\langle \psi \vert (c+\mathcal{E})\boldsymbol{I} + (\Omega+\omega_z)\boldsymbol{Z} + \omega_x\boldsymbol{H}\boldsymbol{Z}\boldsymbol{H}\vert \psi \rangle,
$$

<p>which we can rewrite as</p>
$$
(c+\mathcal{E})\langle \psi \vert \boldsymbol{I}\vert \psi \rangle+(\Omega+\omega_z)\langle \psi \vert \boldsymbol{Z}\vert \psi \rangle+\omega_x\langle \psi \boldsymbol{H}\vert \boldsymbol{Z}\vert\boldsymbol{H}\psi \rangle.
$$

<p>The first and second term are to easy to perform a measurement on since we we just need to compute
\( \langle \psi\vert \boldsymbol{I}\vert \psi\rangle \) and \( \langle \psi\vert \boldsymbol{Z}\vert \psi\rangle \).
For the final term we need just to add the action of the Hadamard matrix and we are done.
</p>

<p><b>To do:</b> Set up codes for this using gradient descent and perform a series of measumerents</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="two-qubit-system-and-the-vqe">Two-qubit system and the VQE </h2>

<p>We extend now the system  to a two-qubit system with the following computational
basis states and Hamiltonian matrix written out in terms of Pauli spin
matrices.
</p>

<p>This system can be thought of as composed of two subsystems
\( A \) and \( B \). Each subsystem has computational basis states
</p>

$$
\vert 0\rangle_{\mathrm{A,B}}=\begin{bmatrix} 1 & 0\end{bmatrix}^T \hspace{1cm} \vert 1\rangle_{\mathrm{A,B}}=\begin{bmatrix} 0 & 1\end{bmatrix}^T.
$$

<p>The subsystems could represent single particles or composite many-particle systems of a given symmetry.
This leads to the many-body computational basis states
</p>

$$
\vert 00\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 1 & 0 & 0 &0\end{bmatrix}^T,
$$

<p>and</p>
$$
\vert 01\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 1 & 0 &0\end{bmatrix}^T,
$$

<p>and</p>
$$
\vert 10\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 1 &0\end{bmatrix}^T,
$$

<p>and finally</p>
$$
\vert 11\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 0 &1\end{bmatrix}^T.
$$

<p>These computational basis states define also the eigenstates of the non-interacting  Hamiltonian</p>
$$
H_0\vert 00 \rangle = \epsilon_{00}\vert 00 \rangle,
$$

$$
H_0\vert 10 \rangle = \epsilon_{10}\vert 10 \rangle,
$$

$$
H_0\vert 01 \rangle = \epsilon_{01}\vert 01 \rangle,
$$

<p>and</p>
$$
H_0\vert 11 \rangle = \epsilon_{11}\vert 11 \rangle.
$$

<p>The interacting part of the Hamiltonian \( H_{\mathrm{I}} \) is given by the tensor product of two \( \sigma_x \) and \( \sigma_z \)  matrices, respectively, that is</p>
$$
H_{\mathrm{I}}=H_x\sigma_x\otimes\sigma_x+H_z\sigma_z\otimes\sigma_z,
$$

<p>where \( H_x \) and \( H_z \) are interaction strength parameters. Our final Hamiltonian matrix is given by</p>
$$
\boldsymbol{H}=\begin{bmatrix} \epsilon_{00}+H_z & 0 & 0 & H_x \\
                       0  & \epsilon_{10}-H_z & H_x & 0 \\
		       0 & H_x & \epsilon_{01}-H_z & 0 \\
		       H_x & 0 & 0 & \epsilon_{11} +H_z \end{bmatrix}.
$$

<p>The four eigenstates of the above Hamiltonian matrix can in turn be used to
define density matrices. As an example, the density matrix of the
first eigenstate (lowest energy \( E_0 \)) \( \Psi_0 \) is
</p>

$$
\rho_0=\left(\alpha_{00}\vert 00 \rangle\langle 00\vert+\alpha_{10}\vert 10 \rangle\langle 10\vert+\alpha_{01}\vert 01 \rangle\langle 01\vert+\alpha_{11}\vert 11 \rangle\langle 11\vert\right),
$$

<p>where the coefficients \( \alpha_{ij} \) are the eigenvector coefficients
resulting from the solution of the above eigenvalue problem.
</p>

<!-- ------------------- end of main content --------------- -->
<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2023, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license
</center>
</body>
</html>

