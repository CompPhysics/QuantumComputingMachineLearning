TITLE: Quantum Computing and many-body problems
AUTHOR: "FYS5419/9419":"https://www.uio.no/studier/emner/matnat/fys/FYS5419/index-eng.html", Quantum computing and quantum machine learning, University of Oslo, Norway
DATE: Spring semester 2023


======= Project suggestion  =======

The aim of this project is to study the so-called Lipkin model (which is a simplified Hamiltonian) using the VQE algorithm.
We will follow closely the article at URL:"https://journals.aps.org/prc/pdf/10.1103/PhysRevC.106.024319". 

===== Part a) =====

Write a function which sets up a one-qubit basis and apply the various
Pauli matrices to these basis states.  Apply the Hadamard and Phase
gates to the same one-qubit basis states and study their actions on
these states. Define also Bell states and write a code where you
implement a Hadamard gate and thereafter a _CNOT_ gate on one of the Bell
states of your choice. Perform thereafter a measurement on the first qubit and
thereafter on the second qubit. The measurements should be performed 
several times and it is the average results of these measurements
which should be discussed and presented.

Compare your code with the results obtained using _Qiskit_, see the
example at
URL:"https://quantum-computing.ibm.com/composer/docs/iqx/first-circuit".





===== Part b) =====

We define a  symmetric matrix  $H\in {\mathbb{R}}^{2\times 2}$
!bt
\[
H = \begin{bmatrix} H_{11} & H_{12} \\ H_{21} & H_{22}
\end{bmatrix},
\]
!et
We  let $H = H_0 + H_I$, where
!bt
\[
H_0= \begin{bmatrix} E_1 & 0 \\ 0 & E_2\end{bmatrix},
\]
!et
is a diagonal matrix. Similarly,
!bt
\[
H_I= \begin{bmatrix} V_{11} & V_{12} \\ V_{21} & V_{22}\end{bmatrix},
\]
!et
where $V_{ij}$ represent various interaction matrix elements.
We can view $H_0$ as the non-interacting solution
!bt
\begin{equation}
       H_0\vert 0 \rangle =E_1\vert 0 \rangle,
\end{equation}
!et
and
!bt
\begin{equation}
       H_0\vert 1\rangle =E_2\vert 1\rangle,
\end{equation}
!et
where we have defined the orthogonal computational one-qubit basis states $\vert 0\rangle$ and $\vert 1\rangle$.




We rewrite $H$ (and $H_0$ and $H_I$)  via Pauli matrices
!bt
\[
H_0 = \mathcal{E} I + \Omega \sigma_z, \quad \mathcal{E} = \frac{E_1
  + E_2}{2}, \; \Omega = \frac{E_1-E_2}{2},
\]
!et
and
!bt
\[
H_I = c \bm{I} +\omega_z\sigma_z + \omega_x\sigma_x,
\]
!et
with $c = (V_{11}+V_{22})/2$, $\omega_z = (V_{11}-V_{22})/2$ and $\omega_x = V_{12}=V_{21}$.
We let our Hamiltonian depend linearly on a strength parameter $\lambda$

!bt
\[
H=H_0+\lambda H_\mathrm{I},
\]
!et

with $\lambda \in [0,1]$, where the limits $\lambda=0$ and $\lambda=1$
represent the non-interacting (or unperturbed) and fully interacting
system, respectively.  The model is an eigenvalue problem with only
two available states.

Here we set the parameters $E_1=0$,
$E_2=4$, $V_{11}=-V_{22}=3$ and $V_{12}=V_{21}=0.2$.

The non-interacting solutions represent our computational basis.
Pertinent to our choice of parameters, is that at $\lambda\geq 2/3$,
the lowest eigenstate is dominated by $\vert 1\rangle$ while the upper
is $\vert 0 \rangle$. At $\lambda=1$ the $\vert 0 \rangle$ mixing of
the lowest eigenvalue is $1\%$ while for $\lambda\leq 2/3$ we have a
$\vert 0 \rangle$ component of more than $90\%$.  The character of the
eigenvectors has therefore been interchanged when passing $z=2/3$. The
value of the parameter $V_{12}$ represents the strength of the coupling
between the two states..


Solve _by standard eigenvalue solvers_ (either numerically or analytically) the above eigenvalue problem.
Find the two eigenvalues as function of the interaction strength $\lambda$.
Study the behavior of these eigenstates as functions of the interaction strength $\lambda$.
Comment your results.


===== Part c) =====

Implement now the variational quantum eigensolver (VQE) for the above
Hamiltonian and set up the circuit(s) which is(are) needed in order to find
the eigenvalues of this system. Discuss the results and compare these
with those from part b). Feel free to use either _Qiskit_ or your own
code (based on the setup from part a)) or both approaches. Discuss
your results.


===== Part d) =====

Extend part c) to a two-qubit system with the following computational
basis states and Hamiltonian matrix written out in terms of Pauli spin
matrices.

This system can be thought of as composed of two subsystems
$A$ and $B$. Each subsystem has computational basis states

!bt
\[
\vert 0\rangle_{\mathrm{A,B}}=\begin{bmatrix} 1 & 0\end{bmatrix}^T \hspace{1cm} \vert 1\rangle_{\mathrm{A,B}}=\begin{bmatrix} 0 & 1\end{bmatrix}^T.
\]
!et
The subsystems could represent single particles or composite many-particle systems of a given symmetry.
This leads to the many-body computational basis states

!bt
\[
\vert 00\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 1 & 0 & 0 &0\end{bmatrix}^T,
\]
!et
and
!bt
\[
\vert 01\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 1 & 0 &0\end{bmatrix}^T,
\]
!et
and
!bt
\[
\vert 10\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 1 &0\end{bmatrix}^T,
\]
!et
and finally
!bt
\[
\vert 11\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 0 &1\end{bmatrix}^T.
\]
!et

These computational basis states define also the eigenstates of the non-interacting  Hamiltonian
!bt
\[
H_0\vert 00 \rangle = \epsilon_{00}\vert 00 \rangle,
\]
!et
!bt
\[
H_0\vert 10 \rangle = \epsilon_{10}\vert 10 \rangle,
\]
!et
!bt
\[
H_0\vert 01 \rangle = \epsilon_{01}\vert 01 \rangle,
\]
!et
and
!bt
\[
H_0\vert 11 \rangle = \epsilon_{11}\vert 11 \rangle.
\]
!et
The interacting part of the Hamiltonian $H_{\mathrm{I}}$ is given by the tensor product of two $\sigma_x$ and $\sigma_z$  matrices, respectively, that is
!bt
\[
H_{\mathrm{I}}=H_x\sigma_x\otimes\sigma_x+H_z\sigma_z\otimes\sigma_z,
\]
!et
where $H_x$ and $H_z$ are interaction strength parameters. Our final Hamiltonian matrix is given by
!bt
\[
\bm{H}=\begin{bmatrix} \epsilon_{00}+H_z & 0 & 0 & H_x \\
                       0  & \epsilon_{10}-H_z & H_x & 0 \\
		       0 & H_x & \epsilon_{01}-H_z & 0 \\
		       H_x & 0 & 0 & \epsilon_{11} +H_z \end{bmatrix}.
\] 
!et

The four eigenstates of the above Hamiltonian matrix can in turn be used to
define density matrices. As an example, the density matrix of the
first eigenstate (lowest energy $E_0$) $\Psi_0$ is

!bt
\[
\rho_0=\left(\alpha_{00}\vert 00 \rangle\langle 00\vert+\alpha_{10}\vert 10 \rangle\langle 10\vert+\alpha_{01}\vert 01 \rangle\langle 01\vert+\alpha_{11}\vert 11 \rangle\langle 11\vert\right),
\]
!et

where the coefficients $\alpha_{ij}$ are the eigenvector coefficients
resulting from the solution of the above eigenvalue problem.


We can
then in turn define the density matrix for the subsets $A$ or $B$ as

!bt
\[
\rho_A=\mathrm{Tr}_B(\rho_{0})=\langle 0 \vert \rho_{0} \vert 0\rangle_{B}+\langle 1 \vert \rho_{0} \vert 1\rangle_{B},
\]
!et

or

!bt
\[
\rho_B=\mathrm{Tr}_A(\rho_0)=\langle 0 \vert \rho_{0} \vert 0\rangle_{A}+\langle 1 \vert \rho_{0} \vert 1\rangle_{A}.
\]
!et

The density matrices for these subsets can be used to compute the
so-called von Neumann entropy, which is one of the possible measures
of entanglement. A pure state has entropy equal zero while entangled
state have an entropy larger than zero. The von-Neumann entropy is
defined as

!bt
\[
S(A,B)=-\mathrm{Tr}\left(\rho_{A,B}\log_2 (\rho_{A,B})\right).
\]
!et


You can select parameter values (or other of your choice)
!bc pycod
Hx = 2.0
Hz = 3.0
# H_0
Energiesnoninteracting = [0.0, 2.5, 6.5, 7.0]
!ec

Compute the eigenvalues _using standard eigenvalue solvers_ as functions of
the interaction strength $\lambda$ and study the role of entanglement.
Compute thereafter the Von Neumann entropy for one of the subsystems using the denisty matrix  of the lowest
two-body state . Comment your results.

The example here shows the above von Neumann entropy based on the
density matrix for the lowest many-body state. We see clearly a jump
in the entropy around the point where we have a level crossing. At
interaction strenght $\lambda=0$ we have many-body states purely
defined by their computational basis states. As we switch on the
interaction strength, we obtain an increased degree of mixing and the
entropy increases till we reach the level crossing point where we see
an additional and sudden increase in entropy. Similar behaviors are
observed for the other states. The most important result from this
example is that entanglement is driven by the Hamiltonian itself and
the strength of the interaction matrix elements and the
non-interacting energies.


===== Part e) =====

Compute now the eigenvalues of this system using the VQE method and
set up the circuits needed to find the lowest state. Compare these
results with those from the previous part. Feel free again to either
use your own code for the circuit and your VQE code or use the
functionality of "Qiskit":"https://qiskit.org/", or both.

===== Part f) =====

We introduce now the Lipkin Hamiltonian and study this for the
$3\times 3$ matrix case with total spin $J=1$ and the $5\times 5$
matrix for the $J=2$ case.
We will follow closely the article in the Physical Review C, volume 106, see URL:"https://journals.aps.org/prc/pdf/10.1103/PhysRevC.106.024319".

The Hamiltonian in second quantization is given by
!bt
\[
H = H_0 + H_1 +H_2,
\]
!et
with 
!bt
\[
H_0 = \frac{1}{2} \varepsilon \sum_{p\sigma}\sigma a_{p\sigma}^{\dagger}a_{p\sigma},
\]
!et
and
!bt
\[
H_1 = \frac{1}{2} V \sum_{p,p',\sigma} a_{p\sigma}^\dagger a_{p'\sigma}^\dagger a_{p'-\sigma} a_{p-\sigma},
\]
!et
and
!bt
\[
H_{2} = \frac{1}{2} W \sum_{p,p',\sigma}a_{p\sigma}^\dagger a_{p'-\sigma}^\dagger a_{p'\sigma}a_{p-\sigma}.
\]
!et
We can rewrite this Hamiltonian in terms of the so-called quasispin operators leading to
!bt
\begin{equation}
H_0 = \varepsilon J_z,
\end{equation}
!et
and
!bt
\begin{equation}
H_1 = \frac{1}{2} V \left( J_+^2 + J_-^2 \right).
\end{equation}
!et
!bt
\begin{equation}
H_2 = \frac{1}{2} W \left( -N + J_+ J_- + J_- J_+ \right).
\end{equation}
!et



We start here with a simpler case, namely the $J=1$ case and we set $W=0$. Show that Hamiltonian matrix is then given by
!bt
\begin{equation}
H_{J = 1} =
\begin{pmatrix}-\epsilon & 0 & -V\\
 0&0&0\\
 -V&0&\epsilon
\end{pmatrix}
\end{equation}
!et


To solve the above hamiltonian problem on a quantum computer we need
to rewrite the Hamiltonian in terms of the Pauli spin
matrices. Rewrite the above $J=1$ Hamiltonian (with $N=2$ particles)
in terms of the Pauli matrices and the identity matrix.


For $J=2$ we have a $5\times 5$ matrix given by
!bt
\begin{equation}
H_{J = 2} =
\begin{pmatrix}
-2\varepsilon & 0 & \sqrt{6}V & 0 & 0 \\
0 & -\varepsilon + 3W & 0 & 3V & 0 \\
\sqrt{6}V & 0 & 4W & 0 & \sqrt{6}V \\
0 & 3V & 0 & \varepsilon + 3W & 0 \\
0 & 0 & \sqrt{6}V & 0 & 2\varepsilon
\end{pmatrix}

\end{equation}
!et

Find also the $J=2$ Hamiltonian ($N=4$ particles) in terms of the same matrices (still with $W=0$).

_Challenge:_ Set up the Hamiltonian with the $W$ term as well in terms of the Pauli spin matrices.

Diagonalize thereafter, using classical methods, the above Hamiltonian matrices and find the
eigenvalues as functions of the strength of the interaction $V$ while
keeping the single-particle energies fixed. Comment your results. Feel
free to add the Hartree-Fock results as discussed in the lectures.

===== Part g) =====

Use now the VQE method to find the same eigenvalues as in part f) and
set up the circuits and simulations which are needed. Compare your
results with those from part f) and comment your results.

===== Part h) =====

Try to write your report as a scientific article. You can use the article in the Physical Review C, volume 106, see URL:"https://journals.aps.org/prc/pdf/10.1103/PhysRevC.106.024319" as a template for your report.



===== Introduction to numerical projects =====

Here follows a brief recipe and recommendation on how to write a report for each
project.

  * Give a short description of the nature of the problem and the eventual  numerical methods you have used.

  * Describe the algorithm you have used and/or developed. Here you may find it convenient to use pseudocoding. In many cases you can describe the algorithm in the program itself.

  * Include the source code of your program. Comment your program properly.

  * If possible, try to find analytic solutions, or known limits in order to test your program when developing the code.

  * Include your results either in figure form or in a table. Remember to        label your results. All tables and figures should have relevant captions        and labels on the axes.

  * Try to evaluate the reliabilty and numerical stability/precision of your results. If possible, include a qualitative and/or quantitative discussion of the numerical stability, eventual loss of precision etc.

  * Try to give an interpretation of you results in your answers to  the problems.

  * Critique: if possible include your comments and reflections about the  exercise, whether you felt you learnt something, ideas for improvements and  other thoughts you've made when solving the exercise. We wish to keep this course at the interactive level and your comments can help us improve it.

  * Try to establish a practice where you log your work at the  computerlab. You may find such a logbook very handy at later stages in your work, especially when you don't properly remember  what a previous test version  of your program did. Here you could also record  the time spent on solving the exercise, various algorithms you may have tested or other topics which you feel worthy of mentioning.






===== Format for electronic delivery of report and programs =====

The preferred format for the report is a PDF file. You can also use DOC or postscript formats or as an ipython notebook file.  As programming language we prefer that you choose between C/C++, Fortran2008 or Python. The following prescription should be followed when preparing the report:

  * Send us an email in order  to hand in your projects with a link to your GitHub/Gitlab repository.

  * In your GitHub/GitLab or similar repository, please include a folder which contains selected results. These can be in the form of output from your code for a selected set of runs and input parameters.


Finally, 
we encourage you to collaborate. Optimal working groups consist of 
2-3 students. You can then hand in a common report. 









