TITLE: February 20-24,2023: Quantum Computing, Quantum Machine Learning and Quantum Information Theories
AUTHOR: Morten Hjorth-Jensen {copyright, 1999-present|CC BY-NC} at Department of Physics, University of Oslo & Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University
DATE: today

!split
===== Entanglement and Entropy  =====

!bblock 
o Review of Schmidt decomposition and entanglement from last week, see jupyter-notebook at URL:"https://github.com/CompPhysics/QuantumComputingMachineLearning/blob/gh-pages/doc/pub/week4/ipynb/week4.ipynb"
o More on entanglement
o Entropy and traces of density matrices
_Reading recommendation_: Scherer, Mathematics of Quantum Computations, section 2.3 and chapter 4  
!eblock

* "Video of lecture":"https://youtu.be/gnlGUjKGDts"
* "See also whiteboard notes":"https://github.com/CompPhysics/QuantumComputingMachineLearning/tree/gh-pages/doc/HandWrittenNotes/2023/NotesFebruary20.pdf"


===== Density matrices and traces =====

In order to study entanglement and why it is so important for quantum
computing, we need to introduce some basic measures and useful
quantities.  For these endeavors, we  will use our two-qubit system from
the second lecture in order to introduce, through examples, density
matrices and entropy. These two quantities, together with
technicalities like the Schmidt decomposition define important quantities in analyzing quantum computing examples.

=== Reminder on density matrices ===

We have the spectral decomposition of a given operator $\bm{A}$ given by

!bt
\[
\bm{A}=\sum_i\lambda_i\vert i \rangle\langle i\vert,
\]
!et
with the ONB $\vert i\rangle$ being eigenvectors of $\bm{A}$ and $\lambda_i$ being the eigenvectors. Similarly, a operator which is a function of $\bm{A}$ is given by
!bt
\[
f(\bm{A})=\sum_if(\bm{A})\vert i \rangle\langle i\vert.
\]
!et
The trace of a product of matrices is cyclic, that is
!bt
\[
\mathrm{tr}[\bm{ABC}])=\mathrm{tr}[\bm{BCA}])=\mathrm{tr}[\bm{CBA}]),
\]
!et
and we have also 
!bt
\[
\mathrm{tr}[\bm{A}\vert \psi\rangle\langle\psi\vert])=\langle\psi\vert\bm{A}\vert\psi\rangle.
\]
!et

Using the spectral decomposition we defined also the density matrix as
!bt
\[
\rho = \sum_i p_i\vert i \rangle\langle i\vert,
\]
!et
where the probability $p_i$ are the eigenvalues of the density linked with the ONB $\vert i \rangle$.

The trace of the density matrix $\mathrm{tr}\rho=1$ and is invariant under unitary transformations
$\vert \psi_i'\rangle = \bm{U}\vert \psi_i\rangle$. The unitary transformation of the density matrix gives, with
$\bm{U}^{\dagger}\bm{U}=\bm{U}^{T}\bm{U}=\bm{I}$,
!bt
\[
\bm{U}\rho\bm{U}^{\dagger}}=\sum_ipi_i\bm{U}\vert \psi_i\rangle\langle\psi_i\vert\bm{U}^{\dagger},
\]
!et
and with the unitary transformation it is easy to show that thet trace of the transformaed density matrix is equal to one,
!bt
\[
\mathrm{tr}\left[ \bm{U}\rho\bm{U}^{\dagger}\right]=\mathrm{tr}\left[ \bm{U}\bm{U}^{\dagger}\rho\right]=1.
\]
!et



=== Two-qubit system and definition of density matrices  ===

This system can be thought of as composed of two subsystems
$A$ and $B$. Each subsystem has computational basis states

!bt
\[
\vert 0\rangle_{\mathrm{A,B}}=\begin{bmatrix} 1 & 0\end{bmatrix}^T \hspace{1cm} \vert 1\rangle_{\mathrm{A,B}}=\begin{bmatrix} 0 & 1\end{bmatrix}^T.
\]
!et
The subsystems could represent single particles or composite many-particle systems of a given symmetry.
This leads to the many-body computational basis states

!bt
\[
\vert 00\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 1 & 0 & 0 &0\end{bmatrix}^T,
\]
!et
and
!bt
\[
\vert 01\rangle = \vert 0\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 1 & 0 &0\end{bmatrix}^T,
\]
!et
and
!bt
\[
\vert 10\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 0\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 1 &0\end{bmatrix}^T,
\]
!et
and finally
!bt
\[
\vert 11\rangle = \vert 1\rangle_{\mathrm{A}}\otimes \vert 1\rangle_{\mathrm{B}}=\begin{bmatrix} 0 & 0 & 0 &1\end{bmatrix}^T.
\]
!et

These computational basis states define also the eigenstates of the non-interacting  Hamiltonian
!bt
\[
H_0\vert 00 \rangle = \epsilon_{00}\vert 00 \rangle,
\]
!et
!bt
\[
H_0\vert 10 \rangle = \epsilon_{10}\vert 10 \rangle,
\]
!et
!bt
\[
H_0\vert 01 \rangle = \epsilon_{01}\vert 01 \rangle,
\]
!et
and
!bt
\[
H_0\vert 11 \rangle = \epsilon_{11}\vert 11 \rangle.
\]
!et
The interacting part of the Hamiltonian $H_{\mathrm{I}}$ is given by the tensor product of two $\sigma_x$ and $\sigma_z$  matrices, respectively, that is
!bt
\[
H_{\mathrm{I}}=H_x\sigma_x\otimes\sigma_x+H_z\sigma_z\otimes\sigma_z,
\]
!et
where $H_x$ and $H_z$ are interaction strength parameters. Our final Hamiltonian matrix is given by
!bt
\[
\bm{H}=\begin{bmatrix} \epsilon_{00}+H_z & 0 & 0 & H_x \\
                       0  & \epsilon_{10}-H_z & H_x & 0 \\
		       0 & H_x & \epsilon_{01}-H_z & 0 \\
		       H_x & 0 & 0 & \epsilon_{11} +H_z \end{bmatrix}.
\] 
!et

The four eigenstates of the above Hamiltonian matrix can in turn be used to
define density matrices. As an example, the density matrix of the
first eigenstate (lowest energy $E_0$) $\Psi_0$ is

!bt
\[
\rho_0=\left(\alpha_{00}\vert 00 \rangle\langle 00\vert+\alpha_{10}\vert 10 \rangle\langle 10\vert+\alpha_{01}\vert 01 \rangle\langle 01\vert+\alpha_{11}\vert 11 \rangle\langle 11\vert\right),
\]
!et

where the coefficients $\alpha_{ij}$ are the eigenvector coefficients
resulting from the solution of the above eigenvalue problem.


We can
then in turn define the density matrix for the subsets $A$ or $B$ as

!bt
\[
\rho_A=\mathrm{Tr}_B(\rho_{0})=\langle 0 \vert \rho_{0} \vert 0\rangle_{B}+\langle 1 \vert \rho_{0} \vert 1\rangle_{B},
\]
!et

or

!bt
\[
\rho_B=\mathrm{Tr}_A(\rho_0)=\langle 0 \vert \rho_{0} \vert 0\rangle_{A}+\langle 1 \vert \rho_{0} \vert 1\rangle_{A}.
\]
!et

The density matrices for these subsets can be used to compute the
so-called von Neumann entropy, which is one of the possible measures
of entanglement. A pure state has entropy equal zero while entangled
state have an entropy larger than zero. The von-Neumann entropy is
defined as

!bt
\[
S(A,B)=-\mathrm{Tr}\left(\rho_{A,B}\log_2 (\rho_{A,B})\right).
\]
!et

The example here shows the above von Neumann entropy based on the
density matrix for the lowest many-body state. We see clearly a jump
in the entropy around the point where we have a level crossing. At
interaction strenght $\lambda=0$ we have many-body states purely
defined by their computational basis states. As we switch on the
interaction strength, we obtain an increased degree of mixing and the
entropy increases till we reach the level crossing point where we see
an additional and sudden increase in entropy. Similar behaviors are
observed for the other states. The most important result from this
example is that entanglement is driven by the Hamiltonian itself and
the strength of the interaction matrix elements and the
non-interacting energies.

!bc pycod
%matplotlib inline
from  matplotlib import pyplot as plt
import numpy as np
from scipy.linalg import logm, expm
def log2M(a): # base 2 matrix logarithm
    return logm(a)/np.log(2.0)

dim = 4
Hamiltonian = np.zeros((dim,dim))
#number of lambda values
n = 40
lmbd = np.linspace(0.0,1.0,n)
Hx = 2.0
Hz = 3.0
# Non-diagonal part as sigma_x tensor product with sigma_x
sx = np.matrix([[0,1],[1,0]])
sx2 = Hx*np.kron(sx, sx)
# Diagonal part as sigma_z tensor product with sigma_z
sz = np.matrix([[1,0],[0,-1]])
sz2 = Hz*np.kron(sz, sz)
noninteracting = [0.0, 2.5, 6.5, 7.0]
D = np.diag(noninteracting)
Eigenvalue = np.zeros((dim,n))
Entropy = np.zeros(n)

for i in range(n): 
    Hamiltonian = lmbd[i]*(sx2+sz2)+D
    # diagonalize and obtain eigenvalues, not necessarily sorted
    EigValues, EigVectors = np.linalg.eig(Hamiltonian)
    # sort eigenvectors and eigenvalues
    permute = EigValues.argsort()
    EigValues = EigValues[permute]
    EigVectors = EigVectors[:,permute]
    # Compute density matrix for selected system state, here ground state
    DensityMatrix = np.zeros((dim,dim))
    DensityMatrix = np.outer(EigVectors[:,0],EigVectors[:,0])
    # Project down on substates and find density matrix for subsystem
    d = np.matrix([[1,0],[0,1]])
    v1 = [1.0,0.0]
    proj1 = np.kron(v1,d)
    x1 = proj1 @ DensityMatrix @ proj1.T
    v2 = [0.0,1.0]
    proj2 = np.kron(v2,d)
    x2 = proj2 @ DensityMatrix @ proj2.T
    # Total density matrix for subsystem
    total = x1+x2
    # von Neumann Entropy for subsystem 
    Entropy[i] = -np.matrix.trace(total @ log2M(total))
    # Plotting eigenvalues and entropy as functions of interaction strengths
    Eigenvalue[0,i] = EigValues[0]
    Eigenvalue[1,i] = EigValues[1]
    Eigenvalue[2,i] = EigValues[2]
    Eigenvalue[3,i] = EigValues[3]
plt.plot(lmbd, Eigenvalue[0,:] ,'b-',lmbd, Eigenvalue[1,:],'g-',)
plt.plot(lmbd, Eigenvalue[2,:] ,'r-',lmbd, Eigenvalue[3,:],'y-',)
plt.xlabel('$\lambda$')
plt.ylabel('Eigenvalues')
plt.show()
plt.plot(lmbd, Entropy)
plt.xlabel('$\lambda$')
plt.ylabel('Entropy')          
plt.show
!ec





===== Entropies and density matrices =====

"See whiteboard notes":"https://github.com/CompPhysics/QuantumComputingMachineLearning/tree/gh-pages/doc/HandWrittenNotes/2023/NotesFebruary20.pdf"

=== Shannon information entropy ===

We start our discussions with the classical information entropy, or
just Shannon entropy, before we move over to a quantum mechanical way
to define the entropy based on the density matrices discussed earlier.

We define a set of random variables $X=\{x_0,x_1,\dots,x_{n-1}\}$ with probability for an outcome $x\in X$ given by $p_X(x)$, the
information entropy is defined as
!bt
\[
S=-\sum_{x\in X}p_X(x)\log_2{p_X(x)}.
\]
!et

=== Von Neumann entropy ===

!bt
\[
S=-\mathrm{Tr}[\rho\log_2{\rho}].
\]
!et

!bblock Lecture next week
o Quantum circuits and operations
o Simple quantum algorithms
o Quantum Fourier Transforms
!eblock
